{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMv_I3EiF6Rd"
   },
   "source": [
    "# Walidacja krzyżowa, krzywe ROC\n",
    "\n",
    "Teoria do tej części znajduje się tu:\n",
    "\n",
    "https://brain.fuw.edu.pl/edu/index.php/Uczenie_maszynowe_i_sztuczne_sieci_neuronowe/Wykład_Ocena_jakości_klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpPO3J51F6Rj"
   },
   "source": [
    "### Przygotowanie środowiska programistycznego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.optimize as so\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zestaw uczący pobieramy z repozytorium github i wczytujemy używając klasy Pandas DataFrame. Najpierw pobieramy repozytorium z github. Repozytorium zawiera kod do naszych ćwiczeń, oraz przykładowe dane w katalogu \"dane\".\n",
    "\n",
    "```\n",
    "!git clone https://github.com/akalinow/Uczenie_maszynowe -b 2023_2024\n",
    "!ln -s /content/Uczenie_maszynowe/dane/ dane\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dane/reg_log_data.txt\", encoding='latin-1', sep=\",\", names=[\"matematyka\", \"biologia\", \"wynik\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proszę:**\n",
    "* skopiować to tego notatnika funkcje do trenowania regresji logistycznej napisane na poprzednich zajęciach:\n",
    "\n",
    "```Python\n",
    "logistic_func(theta, x)\n",
    "log_likelihood(theta, x, y, model)\n",
    "negative_log_likelihood(theta, x, y, model)\n",
    "log_likelihood_derivative(theta, x, y, model)\n",
    "negative_log_likelihood_derivative(theta, x, y, model)\n",
    "classification(theta, x, model)\n",
    "```\n",
    "\n",
    "Oczekiwany wynik (adresy funkcji będą inne niż poniżej):\n",
    "```Python\n",
    "<function logistic_func at 0x7f2a697b2a60> <function log_likelihood at 0x7f2a697b2ca0>\n",
    "<function negative_log_likelihood at 0x7f2a697b28b0> <function log_likelihood_derivative at 0x7f2a697b2ee0>\n",
    "<function negative_log_likelihood_derivative at 0x7f2a697b2670>\n",
    "<function classification at 0x7f2a73884940>\n",
    "Wartość funkcji log-wiarygodności dla zbioru testowego = -69.31471805599453\n",
    "Wartość pochodnej funkcji log-wiarygodności dla zbioru testowego = [  10.         1200.92165893 1126.28422055]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function logistic_func at 0x139069d00> <function log_likelihood at 0x139069760>\n",
      "<function negative_log_likelihood at 0x139069440> <function log_likelihood_derivative at 0x139069800>\n",
      "<function negative_log_likelihood_derivative at 0x1390699e0>\n",
      "<function classification at 0x139069b20>\n",
      "Wartość funkcji log-wiarygodności dla zbioru testowego = -69.31471805599453\n",
      "Wartość pochodnej funkcji log-wiarygodności dla zbioru testowego = [  10.         1200.92165893 1126.28422055]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def logistic_func(theta, x):\n",
    "    # dodaj kolumne jedynek\n",
    "    x_expanded = np.column_stack((np.ones(x.shape[0]), x))\n",
    "    \n",
    "    # policz argument funkcji\n",
    "    arg = np.dot(theta, x_expanded.T)\n",
    "    # uzyj np.where żeby ograniczyc wartosci parmetru do [-18,18]\n",
    "    arg = np.where(np.abs(arg)<18, arg, 18*np.sign(arg))\n",
    "\n",
    "    return 1.0/(1+np.exp(-arg))\n",
    "\n",
    "def log_likelihood(theta, x, y, model):\n",
    "    result = 0 \n",
    "    model_result = model(theta, x)\n",
    "    result = y*np.log(model_result) + (1-y)*np.log(1-model_result)\n",
    "    result = np.sum(result)\n",
    "    return result\n",
    "\n",
    "def negative_log_likelihood(theta, x, y, model):\n",
    "    return -log_likelihood(theta, x, y, model)\n",
    "\n",
    "def log_likelihood_derivative(theta, x, y, model):\n",
    "    # odpowiedź modelu na dane\n",
    "    model_result = model(theta, x)\n",
    "    \n",
    "    # różnica odpowiedzi modelu i wartości prawdziwej\n",
    "    delta = y - model_result\n",
    "    delta = np.reshape(delta, (-1, 1))\n",
    "\n",
    "    # obliczenie pochodnej wysumowanej po wszyskich przykładach\n",
    "    x_expanded = np.column_stack((np.ones(x.shape[0]), x))\n",
    "\n",
    "    result = delta * x_expanded\n",
    "    result = np.sum(result, axis=0)\n",
    "\n",
    "    #sprawdzenie poprawności rozmiaru wyniku\n",
    "    assert result.shape == theta.shape\n",
    "    return result\n",
    "\n",
    "def negative_log_likelihood_derivative(theta, x, y, model):\n",
    "    return -log_likelihood_derivative(theta, x, y, model)\n",
    "\n",
    "def classification(theta, x, model):\n",
    "    model_result = model(theta, x)\n",
    "    return model_result>0.5\n",
    "\n",
    "print(logistic_func, log_likelihood)\n",
    "print(negative_log_likelihood, log_likelihood_derivative)\n",
    "print(negative_log_likelihood_derivative)\n",
    "print(classification)\n",
    "\n",
    "theta0 = np.array([0,0,0])\n",
    "model = logistic_func\n",
    "llh = log_likelihood(theta0, df[[\"matematyka\",\"biologia\"]], df[\"wynik\"], model)\n",
    "llh_derivative = log_likelihood_derivative(theta0, df[[\"matematyka\",\"biologia\"]], df[\"wynik\"], model)\n",
    "\n",
    "print(\"Wartość funkcji log-wiarygodności dla zbioru testowego = {}\".format(llh))\n",
    "print(\"Wartość pochodnej funkcji log-wiarygodności dla zbioru testowego = {}\".format(llh_derivative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzYhR3-IF6TI"
   },
   "source": [
    "### Zastosowanie w naszym przykładzie\n",
    "Przeprowadzimy kross-walidację typu $leave-one-out$:\n",
    "po kolei odłożymy po jednym przykładzie ze zbioru uczącego i na takim zredukowanym zbiorze nauczymy regresję, a następnie sprawdzimy \n",
    "działanie modelu na odłożonym przykładzie. Kroki są następujące:\n",
    "\n",
    "* ze zbioru uczącego odrzucamy jeden przykład\n",
    "* na pozostałych przykładach \"trenujemy model\", czyli znajdujemy parametry $\\theta$\n",
    "* sprawdzamy działanie modelu na odrzuconym wcześniej przykładzie\n",
    "* procedurę powtarzamy dla wszystkich przykładów w zbiorze uczącym  \n",
    "\n",
    "\n",
    "**Proszę:** \n",
    "\n",
    "* napisać funkcję ```leave_one_out_CV(df, theta, model)``` która:\n",
    "    * przyjmuje zestaw uczący w postaci obiektu DataFrame, początkowe wartości parametrów $\\theta$, oraz model $model$\n",
    "    * implementuje algorytm ```leave-one-out``` i tworzy listę wyników modelu dla każdego przykładu:\n",
    "\n",
    "    ```Python\n",
    "    passed = np.append(passed, classification(theta_opt, df_left_out[[\"matematyka\",\"biologia\"]], model))\n",
    "    ```\n",
    "\n",
    "    * dodaje do obiektu DataFrame kolumnę z wynikami modelu:\n",
    "\n",
    "```Python\n",
    "df[\"model\"] = passed \n",
    "```   \n",
    "\n",
    "* uruchomić funkcję na danych i wypisać zawartość zmodyfikowanego obiektu DataFrame. \n",
    "\n",
    "Oczekiwany wynik to:\n",
    "```Python\n",
    "    matematyka   biologia  wynik  model\n",
    "0    34.623660  78.024693      0    0.0\n",
    "1    30.286711  43.894998      0    0.0\n",
    "2    35.847409  72.902198      0    0.0\n",
    "3    60.182599  86.308552      1    1.0\n",
    "4    79.032736  75.344376      1    1.0\n",
    "..         ...        ...    ...    ...\n",
    "```\n",
    "\n",
    "**Wskazówka**: pętla po wszystkich przykładach może użyć indeksu obiektu DataFrame: `df.index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 20.251182\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349728\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.304014\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.340082\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.347964\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.338839\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348746\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.440820\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349480\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.026785\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 17.529995\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.320267\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349039\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349624\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.173454\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.330321\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.465946\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.184058\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349476\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.769098\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.279114\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348394\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.342284\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349669\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.341571\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.189539\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.811570\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 18.034913\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.250750\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.332635\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.238863\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.330440\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.177243\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.368257\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.270923\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.315661\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 17.948395\n",
      "         Iterations: 20\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.337161\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.112157\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.297819\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.319243\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.343604\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349231\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.596278\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.345254\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.198844\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.342702\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349766\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348974\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349761\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.347871\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349270\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.246772\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.346952\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.341160\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.294531\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349627\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 18.900906\n",
      "         Iterations: 21\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.335047\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.345474\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349301\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349548\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.346247\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349643\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.273873\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.307335\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.290721\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.339582\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349723\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.997697\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349708\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.326661\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349663\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.223961\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.247969\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349725\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.261144\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.861360\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.333657\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.360404\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349052\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.322494\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.236096\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 18.660963\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349711\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.347746\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.884476\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349590\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349743\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.234177\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349714\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349755\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348342\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349091\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.269272\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.192575\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.044141\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349667\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.220454\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349521\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "    matematyka   biologia  wynik  model\n",
      "0    34.623660  78.024693      0    0.0\n",
      "1    30.286711  43.894998      0    0.0\n",
      "2    35.847409  72.902198      0    0.0\n",
      "3    60.182599  86.308552      1    1.0\n",
      "4    79.032736  75.344376      1    1.0\n",
      "..         ...        ...    ...    ...\n",
      "95   83.489163  48.380286      1    1.0\n",
      "96   42.261701  87.103851      1    1.0\n",
      "97   99.315009  68.775409      1    1.0\n",
      "98   55.340018  64.931938      1    0.0\n",
      "99   74.775893  89.529813      1    1.0\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def leave_one_out_CV(df, theta0, model):\n",
    "    # macierz przechowująca wyniki dla danego modelu\n",
    "    passed = np.array([])\n",
    "    # kopia oryginalnych danych\n",
    "    df_with_model = df.copy()\n",
    "    \n",
    "    # pętla po wszystkich przykładach\n",
    "    for leave_out_index in df.index:\n",
    "        # 1. stworz dataframe bez jednego przykladu\n",
    "        df_remained = df_with_model.drop(leave_out_index)\n",
    "\n",
    "        # 2. znajdz optymalne parametry theta\n",
    "        theta_opt = so.fmin_bfgs(\n",
    "            f=negative_log_likelihood, \n",
    "            x0=theta0, args=[df_remained[[\"matematyka\",\"biologia\"]], df_remained[\"wynik\"], model],\n",
    "            fprime=negative_log_likelihood_derivative\n",
    "        )\n",
    "\n",
    "        # 3. stworz dataframe z odrzuconego (pojedynczego) przykladu\n",
    "        df_left_out = df_with_model[df_with_model.index==leave_out_index]\n",
    "\n",
    "        # 4. dodaj wynik modelu do poprzednich wynikow \n",
    "        passed = np.append(passed, classification(theta_opt, df_left_out[[\"matematyka\",\"biologia\"]], model))\n",
    "\n",
    "    # dodajemy wyniki modelu do calego data frame\n",
    "    df_with_model[\"model\"] = passed\n",
    "    # zwracamy data frame powiekszony o kolumne z wynikami modelu\n",
    "    return df_with_model\n",
    "                        \n",
    "theta0 = np.array([0,0,0])\n",
    "model = logistic_func \n",
    "df_with_model = leave_one_out_CV(df, theta0, model)\n",
    "print(df_with_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniujmy następujące przypadki gdy nasz model się myli lub podaje poprawny wynik:\n",
    "\n",
    "* **\"True Positive\" (TP)**:  stan faktyczny jest pozytywny (y=1) i klasyfikator się nie myli (wynik = 1)\n",
    "* **\"True Negative\" (TN)**:  stan faktyczny jest negatywny (y=0) i klasyfikator się nie myli (wynik = 0) \n",
    "* **\"False Positive\" (FP)**: wynik fałszywie pozytywny (fałszywy alarm): stan faktyczny jest negatywny (y=0) ale klasyfikator się  myli (wynik = 1)\n",
    "* **\"False Netative\" (FN)**: przegapiony alarm: stan faktyczny jest pozytywny (y=1) i klasyfikator się myli (wynik = 0)\n",
    "\n",
    "**Proszę** napisać kod, który zlicza warianty TP, TN, FP, FN. Dla naszego zbioru uczącego powinniśmy uzyskać:\n",
    "```Python\n",
    "TP:  55\n",
    "FP:  6\n",
    "TN:  34\n",
    "FN:  5\n",
    "```   \n",
    "\n",
    "**Wskazówka:** \n",
    "* proszę użyć metody ```df.shape[0]``` by zliczać liczbę wierszy w odpowiednio przefiltrowanym obiekcie DataFrame\n",
    "* proszę użyć warunkow logicznych aby wybrać odpowiednie dane i pola `shape[0]` aby dostać liczbę wierszy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 55\n",
      "FP = 6\n",
      "TN = 34\n",
      "FN = 5\n"
     ]
    }
   ],
   "source": [
    "tp = np.sum((df_with_model['wynik'] == True) & (df_with_model['model'] == True))\n",
    "fp = np.sum((df_with_model['wynik'] == False) & (df_with_model['model'] == True))\n",
    "tn = np.sum((df_with_model['wynik'] == False) & (df_with_model['model'] == False))\n",
    "fn = np.sum((df_with_model['wynik'] == True) & (df_with_model['model'] == False))\n",
    "\n",
    "print(\"TP = {}\\nFP = {}\\nTN = {}\\nFN = {}\".format(tp, fp, tn, fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UNsb51DF6TQ"
   },
   "source": [
    "## Krzywa ROC\n",
    "\n",
    "Aby wykreślić krzywą ROC należy przeprowadzić klasyfikację dla wielu możliwych wartości progu dla hipotezy, powyżej którego uznajemy przypadek za należący do klasy 1. W tym celu należy zmodyfikować funkcję ```leave_one_out_CV(df, theta0, model)``` tak by zapisywała prawdopodobieństwo, a nie wynik działania funkcji ```classification```\n",
    "\n",
    "**Proszę:** \n",
    "* napisać funkcję ```leave_one_out_CV_with_prob(df, theta0, model)``` która zapisuje kolumnę z prawdopodobieństwem zamiast wynikiem klasyfikacji:\n",
    "\n",
    "```Python\n",
    "df_with_model[\"model_prob\"] = prob\n",
    "```\n",
    "Oczekiwany wynik:\n",
    "```Python\n",
    "    matematyka   biologia  wynik  model_prob\n",
    "0    34.623660  78.024693      0    0.096880\n",
    "1    30.286711  43.894998      0    0.000042\n",
    "2    35.847409  72.902198      0    0.045567\n",
    "3    60.182599  86.308552      1    0.990292\n",
    "4    79.032736  75.344376      1    0.998191\n",
    "..         ...        ...    ...         ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 20.251182\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349728\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.304014\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.340082\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.347964\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.338839\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348746\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.440820\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349480\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.026785\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 17.529995\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.320267\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349039\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349624\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.173454\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.330321\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.465946\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.184058\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349476\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.769098\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.279114\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348394\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.342284\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349669\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.341571\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.189539\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.811570\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 18.034913\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.250750\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.332635\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.238863\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.330440\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.177243\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.368257\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.270923\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.315661\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 17.948395\n",
      "         Iterations: 20\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.337161\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.112157\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.297819\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.319243\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.343604\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349231\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.596278\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.345254\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.198844\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.342702\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349766\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348974\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349761\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.347871\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349270\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.246772\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.346952\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.341160\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.294531\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349627\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 18.900906\n",
      "         Iterations: 21\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.335047\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.345474\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349301\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349548\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.346247\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349643\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.273873\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.307335\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.290721\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.339582\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349723\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.997697\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349708\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.326661\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349663\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.223961\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.247969\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349725\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.261144\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.861360\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.333657\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.360404\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349052\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.322494\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.236096\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 18.660963\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349711\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.347746\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.884476\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349590\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349743\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.234177\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349714\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349755\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348342\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349091\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.269272\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.192575\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.044141\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349667\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.220454\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349521\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "   matematyka   biologia  wynik  model_prob\n",
      "0   34.623660  78.024693      0    0.096879\n",
      "1   30.286711  43.894998      0    0.000042\n",
      "2   35.847409  72.902198      0    0.045566\n",
      "3   60.182599  86.308552      1    0.990292\n",
      "4   79.032736  75.344376      1    0.998192\n"
     ]
    }
   ],
   "source": [
    "def leave_one_out_CV_with_prob(df, theta0, model):\n",
    "    # macierz przechowująca wartość prawdopodobieństwa\n",
    "    prob = np.array([])\n",
    "    # kopia oryginalnego zestawu danych\n",
    "    df_with_model = df.copy()\n",
    "    # petla po wszystkich przykladach\n",
    "    for leave_out_index in df.index:\n",
    "        # 1. stworz dataframe bez jednego przykladu\n",
    "        df_remained = df_with_model.drop(leave_out_index)\n",
    "\n",
    "        # 2. znajdz optymalne parametry theta\n",
    "        theta_opt = so.fmin_bfgs(\n",
    "            f = negative_log_likelihood,\n",
    "            fprime = negative_log_likelihood_derivative,\n",
    "            x0 = theta0, args=[df_remained[[\"matematyka\",\"biologia\"]], df_remained[\"wynik\"], model]\n",
    "        )\n",
    "\n",
    "        # 3. stworz dataframe z odrzuconego (pojedynczego) przykladu\n",
    "        df_left_out = df_with_model[df_with_model.index == leave_out_index]\n",
    "\n",
    "        # 4. dodajemy wynik modelu do poprzednich\n",
    "        prob = np.append(prob, model(theta_opt, df_left_out[[\"matematyka\",\"biologia\"]]))\n",
    "        \n",
    "    # dodajemy wyniki modelu (prawdopodobienstwa) do calego DataFrame\n",
    "    df_with_model[\"model_prob\"] = prob\n",
    "    # zwracamy data frame powiekszony o kolumne z wynikami modelu (prawdopodobienstwami)\n",
    "    return df_with_model\n",
    "                        \n",
    "theta0 = np.array([0,0,0])\n",
    "model = logistic_func \n",
    "df_with_prob = leave_one_out_CV_with_prob(df, theta0, model)\n",
    "print(df_with_prob.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proszę:**\n",
    "* narysować krzywą ROC oraz obliczyć pole pod nią (ang. area under ROC, AUC)\n",
    "\n",
    "**Wskazówka:**\n",
    "* do obliczenia AUC proszę użyć funkcji z biblioteki ```sklearn```. Nazwę i dokumentację funkcji można znaleźć wpisując w Google hasło \"sklearn roc\"\n",
    "* proszę użyć funkcji klasy ```RocCurveDisplay``` z biblioteki ```sklearn```. Nazwę i dokumentację funkcji można znaleźć wpisując w Google hasło \"RocCurveDisplay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kb/3jqrfg_91312qsz97b4mj_p40000gn/T/ipykernel_7388/702764075.py:10: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend(loc=\"lower right\");\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC wynosi: 0.96\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(df_with_prob['wynik'], df_with_prob['model_prob'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5,5))\n",
    "axs.plot(fpr, tpr, 'b')\n",
    "\n",
    "# krzywa (diagonala) dla klasyfikatora losowo przypisującą kategorie -  najgorsze rozwiązanie\n",
    "plt.plot([0, 1], [0, 1], color='navy', linewidth=3, linestyle='--')\n",
    "plt.legend(loc=\"lower right\");\n",
    "\n",
    "print(\"AUC wynosi:\",\"{:0.2f}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modyfikacja modelu - wybór zmiennych wejściowych do modelu\n",
    "\n",
    "**Proszę:** \n",
    "\n",
    "wykonać trening regresji logistycznej dla modelu, który używa wyniku tylko z jednego egzaminu i narysować na jednym rysunku krzywe ROC dla trzech wariantów:\n",
    "* modelu używającego wyników z obu przedmiotów\n",
    "* modelu używającego tylko wyników z matematyki\n",
    "* modelu używającego tylko wyników z biologii\n",
    "\n",
    "Krok 1: \n",
    "\n",
    "* przerobić funkcję ```leave_one_out_CV_with_prob``` tak by wykonywała obliczenia dla wszystkich trzech wariantów\n",
    "\n",
    "Oczekiwany wynik:\n",
    "```Python\n",
    "   matematyka   biologia  wynik  model_prob  model_prob_matematyka  \\\n",
    "0    34.623660  78.024693      0    0.096879               0.132115   \n",
    "1    30.286711  43.894998      0    0.000042               0.096571   \n",
    "2    35.847409  72.902198      0    0.045566               0.143957   \n",
    "3    60.182599  86.308552      1    0.990292               0.530217   \n",
    "4    79.032736  75.344376      1    0.998192               0.839340   \n",
    "..         ...        ...    ...         ...                    ...  \n",
    "\n",
    "\n",
    "    model_prob_biologia  \n",
    "0              0.816447  \n",
    "1              0.276754  \n",
    "2              0.750268  \n",
    "3              0.875439  \n",
    "4              0.765500  \n",
    "..                  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def leave_one_out_CV_many_models(df, theta0, model):\n",
    "    # macierz przechowująca prawdopodobieństwa dla modelu używającego wszystkich kolumn\n",
    "    prob = np.array([])\n",
    "    # macierz przechowująca prawdopodobieństwa dla modelu używającego tylko wyniki z matematyki\n",
    "    prob_math = np.array([])\n",
    "    # macierz przechowująca prawdopodobieństwa dla modelu używającego tylko wyniki z matematyki\n",
    "    prob_biol = np.array([])\n",
    "    # kopia oaryginalnych danych\n",
    "    df_with_model = df.copy()\n",
    "    \n",
    "    for leave_out_index in df.index:\n",
    "...\n",
    "    # dodajemy wyniki modelu (prawdopodobienstwa) do calego DataFrame\n",
    "    # i zwracamy DataFrame powiększone o kolumny z wynikami trzech modeli\n",
    "    df_with_model[\"model_prob\"] = prob\n",
    "    df_with_model[\"model_prob_matematyka\"] = prob_math\n",
    "    df_with_model[\"model_prob_biologia\"] = prob_biol\n",
    "    return df_with_model\n",
    "                        \n",
    "theta0 = np.array([0,0,0])\n",
    "model = logistic_func \n",
    "df_with_prob = leave_one_out_CV_many_models(df, theta0, model)\n",
    "print(df_with_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 2:\n",
    "\n",
    "* narysować na jednym rysunku krzywe ROC dla wszystkich trzech modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(5,5))\n",
    "lw = 2 #szerokosć linii - line width\n",
    "\n",
    "...\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.title('Receiver operating characteristic for logistic regression');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie domowe \n",
    "\n",
    "Zastosowanie regresji logistycznej do innego rodzaju danych\n",
    "\n",
    "**Proszę:**\n",
    "\n",
    "* narysować krzywą ROC dla modelu wytrenowanego na danych z pracy domowej z poprzednich ćwiczeń\n",
    "* napisać funkcję ```logistic_func_1(theta, x)``` która będzie działać podobnie do oryginalnej, ale dodać w niej do oryginalnych danych 3 kolumny: kolumnę jedynek (tak jak poprzednio), kolumnę $x_{1}^2$, kolumnę $x_{2}^2$, gdzie $x_{1}$ i $x_{2}$ to wyniki z matematyki i biologii odpowiednio.\n",
    "* użyć jej jako modelu podawanego do trenowania w funkcji ```leave_one_out_CV_with_prob(df, theta0, model)```\n",
    "* narysować krzywą ROC dla nowego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "plt.title('Receiver operating characteristic for logistic regression')\n",
    "plt.legend(loc=\"lower right\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def logistic_func_1(theta, x):\n",
    "...\n",
    "\n",
    "theta0 = np.array([0,0,0,0,0])\n",
    "model = logistic_func_1 \n",
    "df_with_prob = leave_one_out_CV_with_prob(df, theta0, model)\n",
    "\n",
    "...\n",
    "plt.title('Receiver operating characteristic for logistic regression');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04_Walidacja_modelu.ipynb",
   "provenance": [
    {
     "file_id": "1QyygSjtzI9iNile4e8Qlcur7Qn0r_VRN",
     "timestamp": 1546856483810
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "4a92c6b51368406ba79cf23ea6c1be11": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6e5e2c335854c40857d817fde071239": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c276665ac3fb4531948d896f79ef1c22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a92c6b51368406ba79cf23ea6c1be11",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6e5e2c335854c40857d817fde071239",
      "value": 100
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
