{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMv_I3EiF6Rd"
   },
   "source": [
    "# Walidacja krzyżowa, krzywe ROC\n",
    "\n",
    "Teoria do tej części znajduje się tu:\n",
    "\n",
    "https://brain.fuw.edu.pl/edu/index.php/Uczenie_maszynowe_i_sztuczne_sieci_neuronowe/Wykład_Ocena_jakości_klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpPO3J51F6Rj"
   },
   "source": [
    "### Przygotowanie środowiska programistycznego"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:14:41.154416Z",
     "start_time": "2024-11-26T16:14:40.880686Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.optimize as so\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zestaw uczący pobieramy z repozytorium github i wczytujemy używając klasy Pandas DataFrame. Najpierw pobieramy repozytorium z github. Repozytorium zawiera kod do naszych ćwiczeń, oraz przykładowe dane w katalogu \"dane\".\n",
    "\n",
    "```\n",
    "!git clone https://github.com/akalinow/Uczenie_maszynowe -b 2023_2024\n",
    "!ln -s /content/Uczenie_maszynowe/dane/ dane\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:14:54.673660Z",
     "start_time": "2024-11-26T16:14:54.666666Z"
    }
   },
   "source": [
    "df = pd.read_csv(\"dane/reg_log_data.txt\", encoding='latin-1', sep=\",\", names=[\"matematyka\", \"biologia\", \"wynik\"])"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proszę:**\n",
    "* skopiować to tego notatnika funkcje do trenowania regresji logistycznej napisane na poprzednich zajęciach:\n",
    "\n",
    "```Python\n",
    "logistic_func(theta, x)\n",
    "log_likelihood(theta, x, y, model)\n",
    "negative_log_likelihood(theta, x, y, model)\n",
    "log_likelihood_derivative(theta, x, y, model)\n",
    "negative_log_likelihood_derivative(theta, x, y, model)\n",
    "classification(theta, x, model)\n",
    "```\n",
    "\n",
    "Oczekiwany wynik (adresy funkcji będą inne niż poniżej):\n",
    "```Python\n",
    "<function logistic_func at 0x7f2a697b2a60> <function log_likelihood at 0x7f2a697b2ca0>\n",
    "<function negative_log_likelihood at 0x7f2a697b28b0> <function log_likelihood_derivative at 0x7f2a697b2ee0>\n",
    "<function negative_log_likelihood_derivative at 0x7f2a697b2670>\n",
    "<function classification at 0x7f2a73884940>\n",
    "Wartość funkcji log-wiarygodności dla zbioru testowego = -69.31471805599453\n",
    "Wartość pochodnej funkcji log-wiarygodności dla zbioru testowego = [  10.         1200.92165893 1126.28422055]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:23:24.654122Z",
     "start_time": "2024-11-26T16:23:24.646090Z"
    }
   },
   "source": [
    "\n",
    "def logistic_func(theta, x):\n",
    "    # dodaj kolumne jedynek\n",
    "    x_expanded = np.column_stack((np.ones(x.shape[0]), x))\n",
    "    \n",
    "    # policz argument funkcji\n",
    "    arg = np.dot(theta, x_expanded.T)\n",
    "    # uzyj np.where żeby ograniczyc wartosci parmetru do [-18,18]\n",
    "    arg = np.where(np.abs(arg)<18, arg, 18*np.sign(arg))\n",
    "\n",
    "    return 1.0/(1+np.exp(-arg))\n",
    "\n",
    "def log_likelihood(theta, x, y, model):\n",
    "    result = 0 \n",
    "    model_result = model(theta, x)\n",
    "    result = y*np.log(model_result) + (1-y)*np.log(1-model_result)\n",
    "    result = np.sum(result)\n",
    "    return result\n",
    "\n",
    "def negative_log_likelihood(theta, x, y, model):\n",
    "    return -log_likelihood(theta, x, y, model)\n",
    "\n",
    "def log_likelihood_derivative(theta, x, y, model):\n",
    "    # odpowiedź modelu na dane\n",
    "    model_result = model(theta, x)\n",
    "    \n",
    "    # różnica odpowiedzi modelu i wartości prawdziwej\n",
    "    delta = y - model_result\n",
    "    delta = np.reshape(delta, (-1, 1))\n",
    "\n",
    "    # obliczenie pochodnej wysumowanej po wszyskich przykładach\n",
    "    x_expanded = np.column_stack((np.ones(x.shape[0]), x))\n",
    "\n",
    "    result = delta * x_expanded\n",
    "    result = np.sum(result, axis=0)\n",
    "\n",
    "    #sprawdzenie poprawności rozmiaru wyniku\n",
    "    assert result.shape == theta.shape\n",
    "    return result\n",
    "\n",
    "def negative_log_likelihood_derivative(theta, x, y, model):\n",
    "    return -log_likelihood_derivative(theta, x, y, model)\n",
    "\n",
    "def classification(theta, x, model):\n",
    "    model_result = model(theta, x)\n",
    "    return model_result>0.5\n",
    "\n",
    "print(logistic_func, log_likelihood)\n",
    "print(negative_log_likelihood, log_likelihood_derivative)\n",
    "print(negative_log_likelihood_derivative)\n",
    "print(classification)\n",
    "\n",
    "theta0 = np.array([0,0,0])\n",
    "model = logistic_func\n",
    "llh = log_likelihood(theta0, df[[\"matematyka\",\"biologia\"]], df[\"wynik\"], model)\n",
    "llh_derivative = log_likelihood_derivative(theta0, df[[\"matematyka\",\"biologia\"]], df[\"wynik\"], model)\n",
    "\n",
    "print(\"Wartość funkcji log-wiarygodności dla zbioru testowego = {}\".format(llh))\n",
    "print(\"Wartość pochodnej funkcji log-wiarygodności dla zbioru testowego = {}\".format(llh_derivative))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function logistic_func at 0x127370fe0> <function log_likelihood at 0x127372700>\n",
      "<function negative_log_likelihood at 0x127372a20> <function log_likelihood_derivative at 0x127372ac0>\n",
      "<function negative_log_likelihood_derivative at 0x127372b60>\n",
      "<function classification at 0x127372c00>\n",
      "Wartość funkcji log-wiarygodności dla zbioru testowego = -69.31471805599453\n",
      "Wartość pochodnej funkcji log-wiarygodności dla zbioru testowego = [  10.         1200.92165893 1126.28422055]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzYhR3-IF6TI"
   },
   "source": [
    "### Zastosowanie w naszym przykładzie\n",
    "Przeprowadzimy kross-walidację typu $leave-one-out$:\n",
    "po kolei odłożymy po jednym przykładzie ze zbioru uczącego i na takim zredukowanym zbiorze nauczymy regresję, a następnie sprawdzimy \n",
    "działanie modelu na odłożonym przykładzie. Kroki są następujące:\n",
    "\n",
    "* ze zbioru uczącego odrzucamy jeden przykład\n",
    "* na pozostałych przykładach \"trenujemy model\", czyli znajdujemy parametry $\\theta$\n",
    "* sprawdzamy działanie modelu na odrzuconym wcześniej przykładzie\n",
    "* procedurę powtarzamy dla wszystkich przykładów w zbiorze uczącym  \n",
    "\n",
    "\n",
    "**Proszę:** \n",
    "\n",
    "* napisać funkcję ```leave_one_out_CV(df, theta, model)``` która:\n",
    "    * przyjmuje zestaw uczący w postaci obiektu DataFrame, początkowe wartości parametrów $\\theta$, oraz model $model$\n",
    "    * implementuje algorytm ```leave-one-out``` i tworzy listę wyników modelu dla każdego przykładu:\n",
    "\n",
    "    ```Python\n",
    "    passed = np.append(passed, classification(theta_opt, df_left_out[[\"matematyka\",\"biologia\"]], model))\n",
    "    ```\n",
    "\n",
    "    * dodaje do obiektu DataFrame kolumnę z wynikami modelu:\n",
    "\n",
    "```Python\n",
    "df[\"model\"] = passed \n",
    "```   \n",
    "\n",
    "* uruchomić funkcję na danych i wypisać zawartość zmodyfikowanego obiektu DataFrame. \n",
    "\n",
    "Oczekiwany wynik to:\n",
    "```Python\n",
    "    matematyka   biologia  wynik  model\n",
    "0    34.623660  78.024693      0    0.0\n",
    "1    30.286711  43.894998      0    0.0\n",
    "2    35.847409  72.902198      0    0.0\n",
    "3    60.182599  86.308552      1    1.0\n",
    "4    79.032736  75.344376      1    1.0\n",
    "..         ...        ...    ...    ...\n",
    "```\n",
    "\n",
    "**Wskazówka**: pętla po wszystkich przykładach może użyć indeksu obiektu DataFrame: `df.index`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:23:26.594107Z",
     "start_time": "2024-11-26T16:23:25.647211Z"
    }
   },
   "source": [
    "def leave_one_out_CV(df, theta0, model):\n",
    "    # macierz przechowująca wyniki dla danego modelu\n",
    "    passed = np.array([])\n",
    "    # kopia oryginalnych danych\n",
    "    df_with_model = df.copy()\n",
    "    \n",
    "    # pętla po wszystkich przykładach\n",
    "    for leave_out_index in df.index:\n",
    "        # 1. stworz dataframe bez jednego przykladu\n",
    "        df_remained = df_with_model.drop(leave_out_index)\n",
    "\n",
    "        # 2. znajdz optymalne parametry theta\n",
    "        theta_opt = so.fmin_bfgs(\n",
    "            f=negative_log_likelihood, \n",
    "            x0=theta0, args=[df_remained[[\"matematyka\",\"biologia\"]], df_remained[\"wynik\"], model],\n",
    "            fprime=negative_log_likelihood_derivative\n",
    "        )\n",
    "\n",
    "        # 3. stworz dataframe z odrzuconego (pojedynczego) przykladu\n",
    "        df_left_out = df_with_model[df_with_model.index==leave_out_index]\n",
    "\n",
    "        # 4. dodaj wynik modelu do poprzednich wynikow \n",
    "        passed = np.append(passed, classification(theta_opt, df_left_out[[\"matematyka\",\"biologia\"]], model))\n",
    "\n",
    "    # dodajemy wyniki modelu do calego data frame\n",
    "    df_with_model[\"model\"] = passed\n",
    "    # zwracamy data frame powiekszony o kolumne z wynikami modelu\n",
    "    return df_with_model\n",
    "                        \n",
    "theta0 = np.array([0,0,0])\n",
    "model = logistic_func \n",
    "df_with_model = leave_one_out_CV(df, theta0, model)\n",
    "print(df_with_model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 20.251182\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349728\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.304014\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.340082\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.347964\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.338839\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348746\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.440820\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349480\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.026785\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 17.529995\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.320267\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349039\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349624\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.173454\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.330321\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.465946\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.184058\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349476\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.769098\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.279114\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348394\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.342284\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349669\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.341571\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.189539\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.811570\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 18.034913\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.250750\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.332635\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.238863\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.330440\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.177243\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.368257\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.270923\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.315661\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 17.948395\n",
      "         Iterations: 20\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.337161\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.112157\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.297819\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.319243\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.343604\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349231\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.596278\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.345254\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.198844\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.342702\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349766\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348974\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349761\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.347871\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349270\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.246772\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.346952\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.341160\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.294531\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349627\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 18.900906\n",
      "         Iterations: 21\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.335047\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.345474\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349301\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349548\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.346247\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349643\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.273873\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.307335\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.290721\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.339582\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349723\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.997697\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349708\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.326661\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349663\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.223961\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.247969\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349725\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.261144\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.861360\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.333657\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.360404\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349052\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.322494\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.236096\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 18.660963\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349711\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.347746\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.884476\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349590\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349743\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.234177\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349714\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349755\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348342\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349091\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.269272\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.192575\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.044141\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349667\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.220454\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349521\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "    matematyka   biologia  wynik  model\n",
      "0    34.623660  78.024693      0    0.0\n",
      "1    30.286711  43.894998      0    0.0\n",
      "2    35.847409  72.902198      0    0.0\n",
      "3    60.182599  86.308552      1    1.0\n",
      "4    79.032736  75.344376      1    1.0\n",
      "..         ...        ...    ...    ...\n",
      "95   83.489163  48.380286      1    1.0\n",
      "96   42.261701  87.103851      1    1.0\n",
      "97   99.315009  68.775409      1    1.0\n",
      "98   55.340018  64.931938      1    0.0\n",
      "99   74.775893  89.529813      1    1.0\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniujmy następujące przypadki gdy nasz model się myli lub podaje poprawny wynik:\n",
    "\n",
    "* **\"True Positive\" (TP)**:  stan faktyczny jest pozytywny (y=1) i klasyfikator się nie myli (wynik = 1)\n",
    "* **\"True Negative\" (TN)**:  stan faktyczny jest negatywny (y=0) i klasyfikator się nie myli (wynik = 0) \n",
    "* **\"False Positive\" (FP)**: wynik fałszywie pozytywny (fałszywy alarm): stan faktyczny jest negatywny (y=0) ale klasyfikator się  myli (wynik = 1)\n",
    "* **\"False Netative\" (FN)**: przegapiony alarm: stan faktyczny jest pozytywny (y=1) i klasyfikator się myli (wynik = 0)\n",
    "\n",
    "**Proszę** napisać kod, który zlicza warianty TP, TN, FP, FN. Dla naszego zbioru uczącego powinniśmy uzyskać:\n",
    "```Python\n",
    "TP:  55\n",
    "FP:  6\n",
    "TN:  34\n",
    "FN:  5\n",
    "```   \n",
    "\n",
    "**Wskazówka:** \n",
    "* proszę użyć metody ```df.shape[0]``` by zliczać liczbę wierszy w odpowiednio przefiltrowanym obiekcie DataFrame\n",
    "* proszę użyć warunkow logicznych aby wybrać odpowiednie dane i pola `shape[0]` aby dostać liczbę wierszy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:23:26.613282Z",
     "start_time": "2024-11-26T16:23:26.608939Z"
    }
   },
   "source": [
    "tp = np.sum((df_with_model['wynik'] == True) & (df_with_model['model'] == True))\n",
    "fp = np.sum((df_with_model['wynik'] == False) & (df_with_model['model'] == True))\n",
    "tn = np.sum((df_with_model['wynik'] == False) & (df_with_model['model'] == False))\n",
    "fn = np.sum((df_with_model['wynik'] == True) & (df_with_model['model'] == False))\n",
    "\n",
    "print(\"TP = {}\\nFP = {}\\nTN = {}\\nFN = {}\".format(tp, fp, tn, fn))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 55\n",
      "FP = 6\n",
      "TN = 34\n",
      "FN = 5\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UNsb51DF6TQ"
   },
   "source": [
    "## Krzywa ROC\n",
    "\n",
    "Aby wykreślić krzywą ROC należy przeprowadzić klasyfikację dla wielu możliwych wartości progu dla hipotezy, powyżej którego uznajemy przypadek za należący do klasy 1. W tym celu należy zmodyfikować funkcję ```leave_one_out_CV(df, theta0, model)``` tak by zapisywała prawdopodobieństwo, a nie wynik działania funkcji ```classification```\n",
    "\n",
    "**Proszę:** \n",
    "* napisać funkcję ```leave_one_out_CV_with_prob(df, theta0, model)``` która zapisuje kolumnę z prawdopodobieństwem zamiast wynikiem klasyfikacji:\n",
    "\n",
    "```Python\n",
    "df_with_model[\"model_prob\"] = prob\n",
    "```\n",
    "Oczekiwany wynik:\n",
    "```Python\n",
    "    matematyka   biologia  wynik  model_prob\n",
    "0    34.623660  78.024693      0    0.096880\n",
    "1    30.286711  43.894998      0    0.000042\n",
    "2    35.847409  72.902198      0    0.045567\n",
    "3    60.182599  86.308552      1    0.990292\n",
    "4    79.032736  75.344376      1    0.998191\n",
    "..         ...        ...    ...         ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:23:28.782407Z",
     "start_time": "2024-11-26T16:23:27.541944Z"
    }
   },
   "source": [
    "def leave_one_out_CV_with_prob(df, theta0, model):\n",
    "    # macierz przechowująca wartość prawdopodobieństwa\n",
    "    prob = np.array([])\n",
    "    # kopia oryginalnego zestawu danych\n",
    "    df_with_model = df.copy()\n",
    "    # petla po wszystkich przykladach\n",
    "    for leave_out_index in df.index:\n",
    "        # 1. stworz dataframe bez jednego przykladu\n",
    "        df_remained = df_with_model.drop(leave_out_index)\n",
    "\n",
    "        # 2. znajdz optymalne parametry theta\n",
    "        theta_opt = so.fmin_bfgs(\n",
    "            f = negative_log_likelihood,\n",
    "            fprime = negative_log_likelihood_derivative,\n",
    "            x0 = theta0, args=[df_remained[[\"matematyka\",\"biologia\"]], df_remained[\"wynik\"], model]\n",
    "        )\n",
    "\n",
    "        # 3. stworz dataframe z odrzuconego (pojedynczego) przykladu\n",
    "        df_left_out = df_with_model[df_with_model.index == leave_out_index]\n",
    "\n",
    "        # 4. dodajemy wynik modelu do poprzednich\n",
    "        prob = np.append(prob, model(theta_opt, df_left_out[[\"matematyka\",\"biologia\"]]))\n",
    "        \n",
    "    # dodajemy wyniki modelu (prawdopodobienstwa) do calego DataFrame\n",
    "    df_with_model[\"model_prob\"] = prob\n",
    "    # zwracamy data frame powiekszony o kolumne z wynikami modelu (prawdopodobienstwami)\n",
    "    return df_with_model\n",
    "                        \n",
    "theta0 = np.array([0,0,0])\n",
    "model = logistic_func \n",
    "df_with_prob = leave_one_out_CV_with_prob(df, theta0, model)\n",
    "print(df_with_prob.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 20.251182\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349728\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.304014\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.340082\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.347964\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.338839\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348746\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.440820\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349480\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.026785\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 17.529995\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.320267\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349039\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349624\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.173454\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.330321\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.465946\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.184058\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349476\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.769098\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.279114\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348394\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.342284\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349669\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.341571\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.189539\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.811570\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 18.034913\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.250750\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.332635\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.238863\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.330440\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.177243\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.368257\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.270923\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.315661\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 17.948395\n",
      "         Iterations: 20\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.337161\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.112157\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.297819\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.319243\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.343604\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349231\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.596278\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.345254\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.198844\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.342702\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349766\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348974\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349761\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.347871\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349270\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.246772\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.346952\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.341160\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.294531\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349627\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 18.900906\n",
      "         Iterations: 21\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.335047\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.345474\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349301\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349548\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.346247\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349643\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.273873\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.307335\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.290721\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.339582\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349723\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.997697\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349708\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.326661\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349663\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.223961\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.247969\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349725\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.261144\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.861360\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.333657\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.360404\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349052\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.322494\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.236096\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 18.660963\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349711\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.347746\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.884476\n",
      "         Iterations: 20\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349590\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349743\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.234177\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349714\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349755\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.348342\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349091\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.269272\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.192575\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.044141\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349667\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 19.220454\n",
      "         Iterations: 21\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.349521\n",
      "         Iterations: 20\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "   matematyka   biologia  wynik  model_prob\n",
      "0   34.623660  78.024693      0    0.096879\n",
      "1   30.286711  43.894998      0    0.000042\n",
      "2   35.847409  72.902198      0    0.045566\n",
      "3   60.182599  86.308552      1    0.990292\n",
      "4   79.032736  75.344376      1    0.998192\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proszę:**\n",
    "* narysować krzywą ROC oraz obliczyć pole pod nią (ang. area under ROC, AUC)\n",
    "\n",
    "**Wskazówka:**\n",
    "* do obliczenia AUC proszę użyć funkcji z biblioteki ```sklearn```. Nazwę i dokumentację funkcji można znaleźć wpisując w Google hasło \"sklearn roc\"\n",
    "* proszę użyć funkcji klasy ```RocCurveDisplay``` z biblioteki ```sklearn```. Nazwę i dokumentację funkcji można znaleźć wpisując w Google hasło \"RocCurveDisplay\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:23:28.921495Z",
     "start_time": "2024-11-26T16:23:28.803530Z"
    }
   },
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(df_with_prob['wynik'], df_with_prob['model_prob'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5,5))\n",
    "axs.plot(fpr, tpr, 'b')\n",
    "\n",
    "# krzywa (diagonala) dla klasyfikatora losowo przypisującą kategorie -  najgorsze rozwiązanie\n",
    "plt.plot([0, 1], [0, 1], color='navy', linewidth=3, linestyle='--')\n",
    "plt.legend(loc=\"lower right\");\n",
    "\n",
    "print(\"AUC wynosi:\",\"{:0.2f}\".format(roc_auc))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC wynosi: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kb/3jqrfg_91312qsz97b4mj_p40000gn/T/ipykernel_97792/1214648771.py:10: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend(loc=\"lower right\");\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modyfikacja modelu - wybór zmiennych wejściowych do modelu\n",
    "\n",
    "**Proszę:** \n",
    "\n",
    "wykonać trening regresji logistycznej dla modelu, który używa wyniku tylko z jednego egzaminu i narysować na jednym rysunku krzywe ROC dla trzech wariantów:\n",
    "* modelu używającego wyników z obu przedmiotów\n",
    "* modelu używającego tylko wyników z matematyki\n",
    "* modelu używającego tylko wyników z biologii\n",
    "\n",
    "Krok 1: \n",
    "\n",
    "* przerobić funkcję ```leave_one_out_CV_with_prob``` tak by wykonywała obliczenia dla wszystkich trzech wariantów\n",
    "\n",
    "Oczekiwany wynik:\n",
    "```Python\n",
    "   matematyka   biologia  wynik  model_prob  model_prob_matematyka  \\\n",
    "0    34.623660  78.024693      0    0.096879               0.132115   \n",
    "1    30.286711  43.894998      0    0.000042               0.096571   \n",
    "2    35.847409  72.902198      0    0.045566               0.143957   \n",
    "3    60.182599  86.308552      1    0.990292               0.530217   \n",
    "4    79.032736  75.344376      1    0.998192               0.839340   \n",
    "..         ...        ...    ...         ...                    ...  \n",
    "\n",
    "\n",
    "    model_prob_biologia  \n",
    "0              0.816447  \n",
    "1              0.276754  \n",
    "2              0.750268  \n",
    "3              0.875439  \n",
    "4              0.765500  \n",
    "..                  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:23:36.030142Z",
     "start_time": "2024-11-26T16:23:36.024387Z"
    }
   },
   "source": [
    "%%time\n",
    "\n",
    "def leave_one_out_CV_many_models(df, theta0, model):\n",
    "    # macierz przechowująca prawdopodobieństwa dla modelu używającego wszystkich kolumn\n",
    "    prob = np.array([])\n",
    "    # macierz przechowująca prawdopodobieństwa dla modelu używającego tylko wyniki z matematyki\n",
    "    prob_math = np.array([])\n",
    "    # macierz przechowująca prawdopodobieństwa dla modelu używającego tylko wyniki z matematyki\n",
    "    prob_biol = np.array([])\n",
    "    # kopia oaryginalnych danych\n",
    "    df_with_model = df.copy()\n",
    "    \n",
    "    for leave_out_index in df.index:\n",
    "...\n",
    "    # dodajemy wyniki modelu (prawdopodobienstwa) do calego DataFrame\n",
    "    # i zwracamy DataFrame powiększone o kolumny z wynikami trzech modeli\n",
    "    df_with_model[\"model_prob\"] = prob\n",
    "    df_with_model[\"model_prob_matematyka\"] = prob_math\n",
    "    df_with_model[\"model_prob_biologia\"] = prob_biol\n",
    "    return df_with_model\n",
    "                        \n",
    "theta0 = np.array([0,0,0])\n",
    "model = logistic_func \n",
    "df_with_prob = leave_one_out_CV_many_models(df, theta0, model)\n",
    "print(df_with_prob)"
   ],
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 11 (<unknown>, line 12)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001B[0;36m(most recent call last)\u001B[0m:\n",
      "\u001B[0m  File \u001B[1;32m/opt/anaconda3/envs/Introduction-to-Machine-Learning/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577\u001B[0m in \u001B[1;35mrun_code\u001B[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001B[0m\n",
      "\u001B[0m  Cell \u001B[1;32mIn[9], line 1\u001B[0m\n    get_ipython().run_cell_magic('time', '', '\\ndef leave_one_out_CV_many_models(df, theta0, model):\\n    # macierz przechowująca prawdopodobieństwa dla modelu używającego wszystkich kolumn\\n    prob = np.array([])\\n    # macierz przechowująca prawdopodobieństwa dla modelu używającego tylko wyniki z matematyki\\n    prob_math = np.array([])\\n    # macierz przechowująca prawdopodobieństwa dla modelu używającego tylko wyniki z matematyki\\n    prob_biol = np.array([])\\n    # kopia oaryginalnych danych\\n    df_with_model = df.copy()\\n    \\n    for leave_out_index in df.index:\\n...\\n    # dodajemy wyniki modelu (prawdopodobienstwa) do calego DataFrame\\n    # i zwracamy DataFrame powiększone o kolumny z wynikami trzech modeli\\n    df_with_model[\"model_prob\"] = prob\\n    df_with_model[\"model_prob_matematyka\"] = prob_math\\n    df_with_model[\"model_prob_biologia\"] = prob_biol\\n    return df_with_model\\n                        \\ntheta0 = np.array([0,0,0])\\nmodel = logistic_func \\ndf_with_prob = leave_one_out_CV_many_models(df, theta0, model)\\nprint(df_with_prob)\\n')\u001B[0m\n",
      "\u001B[0m  File \u001B[1;32m/opt/anaconda3/envs/Introduction-to-Machine-Learning/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2541\u001B[0m in \u001B[1;35mrun_cell_magic\u001B[0m\n    result = fn(*args, **kwargs)\u001B[0m\n",
      "\u001B[0m  File \u001B[1;32m/opt/anaconda3/envs/Introduction-to-Machine-Learning/lib/python3.11/site-packages/IPython/core/magics/execution.py:1296\u001B[0m in \u001B[1;35mtime\u001B[0m\n    expr_ast = self.shell.compile.ast_parse(expr)\u001B[0m\n",
      "\u001B[0;36m  File \u001B[0;32m/opt/anaconda3/envs/Introduction-to-Machine-Learning/lib/python3.11/site-packages/IPython/core/compilerop.py:86\u001B[0;36m in \u001B[0;35mast_parse\u001B[0;36m\n\u001B[0;31m    return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)\u001B[0;36m\n",
      "\u001B[0;36m  File \u001B[0;32m<unknown>:12\u001B[0;36m\u001B[0m\n\u001B[0;31m    ...\u001B[0m\n\u001B[0m       ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m expected an indented block after 'for' statement on line 11\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krok 2:\n",
    "\n",
    "* narysować na jednym rysunku krzywe ROC dla wszystkich trzech modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(5,5))\n",
    "lw = 2 #szerokosć linii - line width\n",
    "\n",
    "...\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.title('Receiver operating characteristic for logistic regression');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie domowe \n",
    "\n",
    "Zastosowanie regresji logistycznej do innego rodzaju danych\n",
    "\n",
    "**Proszę:**\n",
    "\n",
    "* narysować krzywą ROC dla modelu wytrenowanego na danych z pracy domowej z poprzednich ćwiczeń\n",
    "* napisać funkcję ```logistic_func_1(theta, x)``` która będzie działać podobnie do oryginalnej, ale dodać w niej do oryginalnych danych 3 kolumny: kolumnę jedynek (tak jak poprzednio), kolumnę $x_{1}^2$, kolumnę $x_{2}^2$, gdzie $x_{1}$ i $x_{2}$ to wyniki z matematyki i biologii odpowiednio.\n",
    "* użyć jej jako modelu podawanego do trenowania w funkcji ```leave_one_out_CV_with_prob(df, theta0, model)```\n",
    "* narysować krzywą ROC dla nowego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "plt.title('Receiver operating characteristic for logistic regression')\n",
    "plt.legend(loc=\"lower right\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def logistic_func_1(theta, x):\n",
    "...\n",
    "\n",
    "theta0 = np.array([0,0,0,0,0])\n",
    "model = logistic_func_1 \n",
    "df_with_prob = leave_one_out_CV_with_prob(df, theta0, model)\n",
    "\n",
    "...\n",
    "plt.title('Receiver operating characteristic for logistic regression');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04_Walidacja_modelu.ipynb",
   "provenance": [
    {
     "file_id": "1QyygSjtzI9iNile4e8Qlcur7Qn0r_VRN",
     "timestamp": 1546856483810
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "4a92c6b51368406ba79cf23ea6c1be11": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6e5e2c335854c40857d817fde071239": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c276665ac3fb4531948d896f79ef1c22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a92c6b51368406ba79cf23ea6c1be11",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6e5e2c335854c40857d817fde071239",
      "value": 100
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
