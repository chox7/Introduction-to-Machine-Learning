{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Uogólnienie koncepcji MDP na przypadki ciągłe\n",
    "\n",
    "Klasycznym przykładem problemu, który można sformułować w postaci ciągłego procesu decyzyjnego Markowa jest sterowanie odwróconego wahadła.\n",
    "\n",
    "* Wyobraźmy sobie wózek o masie $M$, który może poruszać się po 1-wymiarowym torze i na tym wózku na zawiasie o jednym stopniu swobody umieszczony jest nieważki pręt o długości $l$ na którego końcu znajduje się punktowa masa $m$.\n",
    "* Zadaniem naszym jest utrzymanie wahadła w pionie poprzez przykładanie do wózka odpowiedniej siły $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://brain.fuw.edu.pl/edu/images/b/b6/Cart-pendulum.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dyskretyzacja\n",
    "\n",
    "* Przestrzeń stanu dla tego problemu jest 4-wymiarowa, bo mamy \n",
    "\n",
    "$$(x,\\dot{x}, \\theta , \\dot{\\theta })$$\n",
    "\n",
    "* Najprostszym pomysłem na zastosowanie do tego przykładu (lub podobnych) metod uczenia ze wzmocnieniem (RL) jest dyskretyzacja przestrzeni stanów i przestrzeni akcji i zastosowanie algorytmów typu iteracja funkcji wartościującej lub iteracja strategii. \n",
    "\n",
    "* Pomysł ten napotyka w praktyce na bardzo poważny problem ze skalowaniem znany jako \"klątwa wymiarów\". \n",
    "Polega ona na tym, że jeśli każdy z $n$ wymiarów przestrzeni próbkujemy na $k$ poziomów to otrzymujemy siatkę o $k^{n}$ węzłów. Widać zatem, że złożoność obliczeniowa będzie rosła wykładniczo z wymiarami przestrzeni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dyskretyzacja akcji\n",
    "\n",
    "* Zazwyczaj w interesujących problemach przestrzeń akcji jest mniej wymiarowa niż przestrzeń stanów ( _pomyślmy o tym, że sterowanie obiektami w wielu grach da się zrealizować za pomocą klawiszy strzałek_ )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Symulator MDP\n",
    "#### Model matematyczny\n",
    "* Zanim przejdziemy do konkretnego algorytmu, wprowadzimy najpierw koncepcję symulatora/modelu dla MDP. \n",
    "\n",
    "* Model jest sposobem na opis $P_{sa}$.\n",
    "\n",
    "* Zakładamy, że model to \"czarna skrzynka\" (kawałek kodu/program), która otrzymuje na wejściu stany i akcje a na wyjściu zwraca nowe stany.\n",
    "\n",
    "$$(s,a) \\rightarrow  [model] \\rightarrow s'$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "W naszym przykładzie z wahadłem modelem jest układ równań opisujących dynamikę wózka i wahadła:\n",
    "\n",
    "$$\\left( M + m \\right) \\ddot{x} - m \\ell \\ddot{\\theta }\\cos \\theta + m \\ell \\dot{\\theta }^2 \\sin \\theta = F$$\n",
    "$$\\ell \\ddot{\\theta }- g \\sin \\theta = \\ddot{x} \\cos \\theta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Możemy go przepisać jako układ równań pierwszego rzędu w którym stan jest 4-wymiarowym wektorem:\n",
    "\n",
    "$$s = \\left[\n",
    "\\begin{array}{ccc}\n",
    "x \\\\\n",
    "\\dot{x} \\\\\n",
    "\\theta \\\\\n",
    "\\dot{\\theta }\\end{array}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Nasz symulator mógłby działać np. całkując ten układ równań metodą Eulera pierwszego rzędu:\n",
    "\n",
    "$$\n",
    "s_{t+1} = s_{t} + \\dot{s} \\Delta t \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Obserwacja modelu fizycznego\n",
    "Jeśli nie umiemy wypisać równań dynamiki układu ale mamy fizyczny model i np. operatora tego modelu to można spróbować rozwiązać go przez obserwację wielu realizacji zachowania układu (model, operator), wg. poniższego algorytmu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Obserwujemy $m$ realizacji stanów i akcji, które doprowadziły do przejść między stanami:\n",
    "\n",
    "$$s_0^{(1)}\\, ^{\\underrightarrow{a_0}^{(1)} } \\, s_1^{(1)}\\, ^{\\underrightarrow{a_1}^{(1)} } \\,  s_2^{(1)} \\cdots \\,  ^{\\underrightarrow{a_{T-1}}^{(1)} } \\, s_T^{(1)} $$\n",
    "$$\\vdots$$\n",
    "$$s_0^{(m)}\\, ^{\\underrightarrow{a_0}^{(m)} } \\, s_1^{(m)}\\, ^{\\underrightarrow{a_1}^{(m)} } \\,  s_2^{(m)} \\cdots \\,  ^{\\underrightarrow{a_{T-1}}^{(m)} } \\, s_T^{(m)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Te realizacje dostarczają nam zbioru uczącego \n",
    "$\\left\\lbrace  (s_{t},a_{t}), s_{t+1}\\right\\rbrace $\n",
    "\n",
    "\n",
    "*\tZa pomocą jednego z algorytmów uczenia nadzorowanego (np. regresja liniowa, regresja liniowa z jądrem, sieci warstwowe z algorytmem wstecznej propagacji błędów itd.) wytwarzamy przybliżenie odwzorowania\n",
    "\n",
    "$$s_{t+1} = f(s_{t},a_{t})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* _Dla ustalenia uwagi załóżmy, że w naszym przykładzie z wahadłem będzie to odwzorowanie liniowe postaci:_\n",
    "$$s_{t+1} = A s_{t} + B a_{t}$$\n",
    "_gdzie $A$ jest macierzą ($4 \\times 4$), zaś $B$ jest wektorem (u nas 4 wymiarowym).\n",
    "Zadaniem algorytmu uczącego byłoby wyznaczenie $A$ i $B$ takich, że:_\n",
    "\n",
    "$$\\arg \\min _{A,B} \\sum _{i=1}^{m}\\sum _{t=0}^{T-1}||s_{t+1}^{(i)} - (A s_{t}^{(i)} +B a_{t}^{(i)})||^{2} $$\n",
    "\n",
    "*\tTeraz mamy dopasowany model, w wersji deterministycznej:\n",
    "\n",
    "$$s_{t+1} = As_{t} + Ba_{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Możemy też rozważać wersję stochastyczną postaci:\n",
    "\n",
    "$$s_{t+1} = As_{t} + Ba_{t} + \\epsilon _{t}$$\n",
    "\n",
    "gdzie $\\epsilon \\sim N(0,\\sigma ^{2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estymacja funkcji wartościującej\n",
    "\n",
    "* W przypadku stanów dyskretnych podawaliśmy funkcję wartościującą $V(s)$ w postaci tablicy wartości: dla każdego stanu mieliśmy przypisaną jakąś liczbę. \n",
    "\n",
    "* Funkcję $V$ można było znaleźć rozwiązując równania Bellmana (dla $n$ stanów mieliśmy układ $n$ równań liniowych z $n$ niewiadomymi). \n",
    "* W przypadku ciągłym nie da się zastosować tego podejścia bezpośrednio. Musimy dopasować jakąś funkcję ciągłą, która przybliżałaby $V$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Można zastosować podejście analogiczne jak przy regresji:\n",
    "  * Najpierw trzeba wybrać jakieś cechy $\\phi (s)$, którymi będziemy charakteryzować stan $s$. \n",
    "    * W najprostszym przypadku może to być sam stan: $\\phi (s) = s$ (w przypadku wahadła $[x,\\dot{x}, \\theta , \\dot{\\theta }]^{T}$). \n",
    "    * Może okazać się korzystne wzbogacenie wektora cech o jakieś dodatkowe składowe np.:\n",
    "$$\\phi (s) = [1, x, \\dot{x}, \\dot{x} ^{2}, \\theta x, \\dot{\\theta }^{2}, \\dots ]^{T}$$\n",
    "* Wówczas funkcję wartościującą można przybliżyć przez:\n",
    "$$V(s) = \\beta ^{T} \\phi (s) $$\n",
    "gdzie $\\beta $ to wektor parametrów regresji liniowej.\n",
    "\n",
    "(Jest to równanie analogiczne do tego, które stosowaliśmy przy regresji liniowej $\\rightarrow $ tam mieliśmy $y = h_{\\theta }(x) = \\theta ^{T} \\phi (x)$, tu żeby nie przeciążać notacji wektor parametrów regresji nazwaliśmy $\\beta $.)\n",
    "\n",
    "Przypomnijmy, że najważniejszym punktem algorytmu iteracji funkcji wartościującej było uaktualnianie funkcji wartości zgodnie z równaniem:\n",
    "\n",
    "$$V(s) = R(s) + \\gamma \\max _{a} \\sum _{s^{\\prime }} P_{sa}V(s^{\\prime })$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "co bardziej ogólnie można wyrazić:\n",
    "\n",
    "$$V(s) = R(s) + \\gamma \\max _{a} E_{s^{\\prime } \\sim P_{sa}}[V(s^{\\prime })]$$\n",
    "\n",
    "Widać, że przejście do przypadku ciągłych stanów wymaga znalezienia sposobu wyznaczania wartości oczekiwanej: $E_{s^{\\prime } \\sim P_{sa}}[V(s^{\\prime })]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Po tym wstępie przyjrzyjmy się algorytmowi dopasowywanej funkcji wartościującej:\n",
    "\n",
    "* Losowo próbkuj $m$ stanów $ s^{1}, s^{(2)}, \\dots , s^{(m)} \\in S$\n",
    "* Inicjalizuj $\\beta = 0$\n",
    "* Powtarzaj {\n",
    "\n",
    "$\\qquad$ Dla $i = 1, \\dots , m \\lbrace $\n",
    "\n",
    "$\\qquad$$\\qquad$Dla każdej akcji $a \\in A$ {\n",
    "\n",
    "$\\qquad$$\\qquad$$\\qquad$Próbkuj $s_{1}^{\\prime }, s_{2}^{\\prime }, \\dots , s_{k}^{\\prime } \\sim P_{s^{(i)}a}$ (używając modelu/symulatora MDP)\n",
    "\n",
    "$\\qquad$$\\qquad$$\\qquad$przypisz $q(a) = \\frac{1}{k} \\sum _{j=1}^{k} R(s^{(i)}) + \\gamma V(s_{j}^{\\prime })$\n",
    "$\\qquad$// wielkość $q(a)$ jest estymatorem $R(s) + \\gamma E_{s^{\\prime } \\sim P_{sa}}[V(s^{\\prime })]$\n",
    "\n",
    "$\\qquad$$\\qquad$$\\qquad$}\n",
    "\n",
    "$\\qquad$$\\qquad$Przypisz $y^{(i)} = \\max _{a} q(a)$$\\qquad$// tak obliczone $y^{(i)}$ jest estymatorem $R(s) + \\gamma \\max _{a} E_{s^{\\prime } \\sim P_{sa}}[V(s^{\\prime })]$\n",
    "\n",
    "$\\qquad$$\\qquad$}\n",
    "\n",
    "$\\qquad$// w wersji dyskretnej alg. iteracji f. wartościującej uaktualnialiśmy\n",
    "\n",
    "$\\qquad$//$V(s^{(i)}) = y^{(i)}$\n",
    "\n",
    "$\\qquad$//w tym algorytmie, ponieważ $V(s)$ nie jest tablicą ale funkcją ciągłą\n",
    "\n",
    "$\\qquad$//dopasowujemy parametry f. wartościującej (jeśli jest liniowa to np. za pomocą regresji liniowej,\n",
    "\n",
    "$\\qquad$//można w tym kroku zastosować jakiś inny algorytm uczenia z nauczycielem)\n",
    "\n",
    "$\\qquad$Przypisz $\\beta = \\arg \\min _{\\beta } \\frac{1}{2} \\sum _{i=1}^{m}(\\beta ^{T} \\phi (s^{(i)}) - y(i))^{2}$\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Zauważmy, że:\n",
    "* w przypadku gdy model/symulator MDP jest deterministyczny to można uprościć powyższy algorytm kładąc $k=1$. Jest tak ponieważ wartość oczekiwana w przypadku deterministycznym jest dokładnie równa wartości obliczonej jako $V(s^{\\prime })$ ($s^{\\prime }$ jest jednoznaczne mając $s$ i $a$). \n",
    "* W przypadku stochastycznym trzeba empirycznie stwierdzić do jakich stanów $s^{\\prime }$ przejdziemy i jaka jest średnia $V(s^{\\prime })$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Jeśli chodzi o funkcję nagrody $R(s)$ zwykle ją zadajemy zgodnie z intuicją wynikającą z problemu. W przypadku wahadła można przyjąć np.:\n",
    "\n",
    "$$ R = \\left\\lbrace  \\begin{array}{ r l}\n",
    "-1 & \\text{gdy wahadło się przewróci } \\\\\n",
    "0 & \\text{w przeciwnym razie}\n",
    "\\end{array} \\right.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Jak wyznaczyć strategię?\n",
    "\n",
    "Algorytm estymowanej funkcji wartościującej oblicza przybliżoną postać funkcji $V^{*}$. Akcje podejmujemy wtedy w następujący sposób:\n",
    "\n",
    "$$a = \\arg \\max _{a} E_{s^{\\prime } \\sim P_{sa} } [V(s^{\\prime })]$$\n",
    "\n",
    "W ogólnym przypadku stochastycznym dla policzenia wartości oczekiwanej w powyższym wzorze konieczne jest pobranie próbki stanów $s^{\\prime } \\sim P_{sa}$ i obliczenie wartości średniej $V(s^{\\prime })$. Istnieją jednak dwa ważne przypadki kiedy można uprościć obliczenia wartości oczekiwanej:\n",
    "* dla modelu/symulator deterministycznego do obliczenia wartości oczekiwanej wystarczy wyliczyć $V(s^{\\prime })$ i wybrać tą akcję, która prowadzi do stanu $s^{\\prime }$ o największej funkcji wartościującej. Zatem mamy:\n",
    "\n",
    "$$a = \\arg \\max _{a} V(f(s,a))$$\n",
    "\n",
    "* dla stochastycznego symulatora/modelu postaci:\n",
    "$$s_{t+1} = f(s_{t},a_{t}) + \\epsilon _{t}$$\n",
    "gdzie $\\epsilon _{t}$ jest próbką szumu gusowskiego $\\sim N(0,\\sigma ^{2})$.\n",
    "\n",
    "W tym przypadku można zastosować przybliżenie:\n",
    "$$E_{s^{\\prime }\\sim P_{sa}}[V^{*}(s^{\\prime })] \\approx V^{*}(E[s^{\\prime }]) = V^{*}(f(s,a))$$\n",
    "\n",
    "I w tym przybliżeniu akcję wybieramy jako:\n",
    "$$a = \\arg \\max _{a} V^*(f(s,a))$$\n",
    "\n",
    "Np. w naszym przykładzie\n",
    "$$V^{*}(s) = \\beta ^{T} \\phi (s) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Przykładowa implementacja kontrolera wahadła\n",
    "\n",
    "Poniższy przykład zaczerpnięto z: http://mechanistician.blogspot.com/2009/05/lec17-fitted-value-iteration_31.html:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Importujemy biblioteki:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available matplotlib backends: ['tk', 'gtk', 'gtk3', 'gtk4', 'wx', 'qt4', 'qt5', 'qt6', 'qt', 'osx', 'nbagg', 'notebook', 'agg', 'svg', 'pdf', 'ps', 'inline', 'ipympl', 'widget']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib --list \n",
    "%matplotlib qt\n",
    "import sys\n",
    "import matplotlib.pylab as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Najpierw napiszemy kilka funkcji pomocniczych. \n",
    "\n",
    "Pierwsza wytwarza wektor cech z podanego wektora stanu \n",
    "\n",
    "( _można tu próbować wzbogacać ten wekotr_ ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def wektor_cech( x,x_dot, theta,theta_dot):\n",
    "    cechy=[1.0,\n",
    "            x,\n",
    "            x_dot,\n",
    "            theta,\n",
    "            theta_dot,\n",
    "            x_dot**2,\n",
    "            theta_dot**2,\n",
    "            theta*x]\n",
    "    return np.array(cechy).reshape(1,len(cechy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Przyda się też funkcja to testowania czy układ nie jest już za bardzo rozchwiany:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "twelve_degrees = 0.2094384 \n",
    "def is_terminal(x,theta):\n",
    "    return -2.4>x or x>2.4 or -twelve_degrees>theta or theta>twelve_degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Teraz stworzymy klasę kontrolera. Będzie ona przydatna do przechowywania stanu i wizualizacji wahadła. Zawiera też funkcję symulującą dynamikę wahadła (model do wytwarzania przykładowych przejść między stanami). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kontroler:\n",
    "    def __init__(self,stan):\n",
    "        self.x = stan[0,1]\n",
    "        self.x_dot = stan[0,2]\n",
    "        self.theta = stan[0,3]\n",
    "        self.theta_dot = stan[0,4] \n",
    "        self.proba = 0\n",
    "        self.num_failures = 0\n",
    "        self.dl = 3\n",
    "        self.start = True\n",
    "        self.g = 9.8\n",
    "        self.mK = 1.0 \n",
    "        self.mW = .3\n",
    "        self.M=self.mW + self.mK\n",
    "        self.len = .7\n",
    "        self.I = self.mW *self.dl**2/3    # moment bezwl. wah.\n",
    "        self.Fmag = 10.0\n",
    "        self.dt = .02\n",
    "        self.akcja_flip_prob = 0.0\n",
    "        self.force_noise_factor = 0.0\n",
    "        self.no_control_prob = 0.0\n",
    "         \n",
    "    def show_kontroler(self, num):\n",
    "        plt.figure(1)\n",
    "        \n",
    "        x1 = self.x\n",
    "        y1 = 0\n",
    "        x2 = self.x + self.dl * np.sin(self.theta)\n",
    "        y2 = self.dl * np.cos(self.theta)\n",
    "           \n",
    "        self.kontroler_x = [self.x-.4,self.x+.4]\n",
    "        self.kontroler_y =[-.125,-.125]\n",
    "        \n",
    "        plt.axis([-3,3,-0.5,3.5])\n",
    "        \n",
    "        if self.start:\n",
    "            self.wahadlo,   = plt.plot([x1,x2],[y1,y2],c='black')\n",
    "            self.kontroler,= plt.plot(self.kontroler_x,self.kontroler_y,c='cyan',lw=16)\n",
    "            self.start = False\n",
    "        else:\n",
    "            self.wahadlo.set_data([x1,x2],[y1,y2])\n",
    "            self.kontroler.set_data(self.kontroler_x,self.kontroler_y)       \n",
    "            plt.title('próba %d'%num)     \n",
    "        plt.draw()\n",
    "        plt.pause(0.01)\n",
    "    \n",
    "    #symulacja zachowania kontrolera\n",
    "    def dynamika_kontrolera(self, akcja, stan): \n",
    "        x = stan[0,1]\n",
    "        x_dot = stan[0,2]\n",
    "        theta = stan[0,3]\n",
    "        theta_dot = stan[0,4]\n",
    "        \n",
    "        if self.akcja_flip_prob > np.random.random(): #dopuszczamy błąd w kierunku siły - podmieniamy akcję na przeciwną\n",
    "            akcja=1-akcja\n",
    "            \n",
    "        if akcja > 0:\n",
    "            F = self.Fmag\n",
    "        else:\n",
    "            F = -self.Fmag\n",
    "        \n",
    "        F = F * (1 - self.force_noise_factor*np.random.uniform(-1,1)) # dopuszczamy fluktuacje siły\n",
    "\n",
    "        if self.no_control_prob > np.random.random():\n",
    "            force=0\n",
    "\n",
    "        costheta = np.cos(theta)\n",
    "        sintheta = np.sin(theta)\n",
    "\n",
    "        temp=(F + self.I * theta_dot**2 * sintheta)/self.M\n",
    "        thetaacc=(self.g*sintheta - costheta*temp)/(self.len*(4/3 -self.mW*costheta**2/self.M))\n",
    "        xacc=temp - self.I*thetaacc*costheta/self.M\n",
    "        \n",
    "        # całkowanie ruchu Euler 1\n",
    "        x += self.dt*self.x_dot\n",
    "        x_dot += self.dt *xacc\n",
    "        theta += self.dt *self.theta_dot\n",
    "        theta_dot += self.dt *thetaacc\n",
    "        return wektor_cech(x,x_dot, theta,theta_dot)\n",
    "     \n",
    "    def uaktualnij(self, stan):\n",
    "        K.x = stan[0,1]\n",
    "        K.x_dot = stan[0,2]\n",
    "        K.theta = stan[0,3]\n",
    "        K.theta_dot = stan[0,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Symulacja \n",
    "Symulujemy zachowanie wahadła począwszy od losowego położenia początkowego wózka i losowego kąta: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(-1.1,1.1)\n",
    "x_dot = 0.0\n",
    "theta = np.random.uniform(-twelve_degrees,twelve_degrees)\n",
    "theta_dot=0.0\n",
    "stan = wektor_cech(x, x_dot, theta, theta_dot)\n",
    "\n",
    "K = kontroler(stan)\n",
    "\n",
    "n = np.shape(stan)[1]\n",
    "m = 1000\n",
    "przykladowe_stany = np.ones((m,n))\n",
    "\n",
    "for i in range(m):\n",
    "    if np.random.random()>.5:\n",
    "        akcja=1\n",
    "    else:\n",
    "        akcja=0    \n",
    "        \n",
    "    stan_nowy = K.dynamika_kontrolera(akcja,stan)\n",
    "    przykladowe_stany[i,:] = stan_nowy\n",
    "\n",
    "    if is_terminal(stan_nowy[0,1],stan_nowy[0,3]):\n",
    "        x = np.random.uniform(-1.1,1.1)\n",
    "        x_dot = 0.0\n",
    "        theta = np.random.uniform(-twelve_degrees,twelve_degrees)\n",
    "        theta_dot = 0.0\n",
    "        stan = wektor_cech(x, x_dot, theta, theta_dot)\n",
    "        K.uaktualnij(stan)\n",
    "    else:\n",
    "        stan = stan_nowy\n",
    "        K.uaktualnij(stan) \n",
    "        K.show_kontroler(i)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estymacja funkcji wartościującej\n",
    "Iteracyjnie estymujemy funkcję $V^*$. $$V^{*}(s) = \\beta ^{T} \\phi (s) $$ \n",
    "W każdym kroku iteracji za pomocą metody najmniejszych kwadratów znajdujemy najlepsze parametry $\\beta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1t/qbjskh415rz70kx6_0rww8680000gp/T/ipykernel_68601/3658986060.py:47: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  result = np.linalg.lstsq(przykladowe_stany,y_vec) # tu fitujemy model liniowy\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.995\n",
    "diff = 10**10   \n",
    "new_diff = diff-1\n",
    "epochs = 0\n",
    "beta = np.zeros((n,1))\n",
    "\n",
    "while 10 > epochs and diff > new_diff:\n",
    "    diff = new_diff\n",
    "    epochs += 1\n",
    "    print(epochs)\n",
    "\n",
    "    y_vec = np.zeros((m,1))   \n",
    "    \n",
    "    for i in range(m):\n",
    "        stan = przykladowe_stany[i,:].reshape(1,n)\n",
    "\n",
    "        # POBRANIE NAGRODY DLA AKTUALNEGO STANU\n",
    "        if is_terminal(stan[0,1],stan[0,3]):\n",
    "            R=-1.0\n",
    "        else:\n",
    "            R=0.0         \n",
    "        \n",
    "        # OBLICZENIE FUNKCJI WARTOŚCIUJĄCEJ DLA AKCJI = 0 \n",
    "        nowy_stan0 = K.dynamika_kontrolera(0, stan)\n",
    "        V1 = R + gamma*np.dot(nowy_stan0, beta)\n",
    "        \n",
    "        # OBLICZENIE FUNKCJI WARTOŚCIUJĄCEJ DLA AKCJI = 1 \n",
    "        nowy_stan1 = K.dynamika_kontrolera(1, stan)\n",
    "        V2 = R + gamma*np.dot(nowy_stan1, beta)\n",
    "        \n",
    "        # \\arg \\max _{a} V(f(s,a))\n",
    "        if V1 > V2:\n",
    "            akcja=0\n",
    "            V = V1\n",
    "        elif V2 > V1:\n",
    "            akcja = 1\n",
    "            V = V2\n",
    "        else:\n",
    "            if np.random.random()>.5:\n",
    "                akcja = 1\n",
    "                V = V2\n",
    "            else:\n",
    "                akcja=0\n",
    "                V = V1\n",
    "        y_vec[i,0] = V\n",
    "    \n",
    "    result = np.linalg.lstsq(przykladowe_stany,y_vec) # tu fitujemy model liniowy\n",
    "    beta = result[0]\n",
    "    new_diff = result[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ilustracja działania nauczonego kontrolera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IoffContext at 0x7f9a6f634f10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <_NSViewBackingLayer: 0x7f9a728e8b70> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <_NSViewBackingLayer: 0x7f9a728e8b70> contents scale of 2 - updating layer to match.\n"
     ]
    }
   ],
   "source": [
    "plt.ion()\n",
    "t = 0\n",
    "\n",
    "stan = wektor_cech(x = 0, x_dot = 0, theta= 0, theta_dot = 0)\n",
    "K.uaktualnij(stan)\n",
    "\n",
    "while True:    \n",
    "    stan0 = K.dynamika_kontrolera(0,stan)\n",
    "    q1 = np.dot(stan0, beta)\n",
    "    \n",
    "    stan1= K.dynamika_kontrolera(1, stan)\n",
    "    q2 = np.dot(stan1, beta)\n",
    "    \n",
    "    if q1 > q2:\n",
    "        akcja = 0\n",
    "    elif q2 > q1:\n",
    "        akcja = 1\n",
    "    else:\n",
    "        if np.random.random()>.5:\n",
    "            akcja=1\n",
    "        else:\n",
    "            akcja=0\n",
    "\n",
    "    stan = K.dynamika_kontrolera(akcja,stan)\n",
    "    K.uaktualnij(stan)\n",
    "    K.show_kontroler(t)\n",
    "    t+=1  \n",
    "    if is_terminal(stan[0,1],stan[0,3]):\n",
    "        break\n",
    "plt.ioff() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "serif",
   "transition": "fade",
   "width": 1600
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
