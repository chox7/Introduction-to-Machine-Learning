{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "tVNInyz7-ypU",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "# Powtórka\n",
    "wyprowadziliśmy metodę uczenia wielowarstwowych sieci nieliniowych bazującą na minimalizacji funkcji kosztu metodą gradientową. W dzisiejszym wykładzie zastanowimy się jak robić to w sposób:\n",
    "* szybszy\n",
    "* zmniejszający ryzyko wpadania w minima lokalne\n",
    "* prowadzący do lepszej generalizacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iosl2KTz-ype",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Twierdzenie o potencjalnych możliwościach sieci\n",
    "Sieć nieliniowa co najmniej dwuwarstwowa może aproksymować dowolną funkcję swoich wejść, ze z góry zadaną dokładnością. Konieczna jest jedynie dostatecznie duża ilość jednostek w warstwach ukrytych. Do aproksymacji dowolnej funkcji ciągłej wystarcza jedna warstwa ukryta. \n",
    "\n",
    "Uzasadnienie nieformalne:\n",
    ">  Każda “rozsądna” funkcja $ F_i{X_k}$ może być przedstawiona jako liniowa kombinacja “wypukłości”, z których każda jest różna od zera tylko w pobliżu $X_k$.\n",
    "> Takie “wypukłości” można skonstruować z dwóch warstw ukrytych. \n",
    "\n",
    "Gdzie jest problem?\n",
    "* twierdzenie mówi jedynie o istnieniu rozwiązania \n",
    "* w ogólności nie wiadomo ile jednostek w warstwach stanowi “dostatecznie dużą ilość”\n",
    "* nie ma gwarancji, że problem da się rozwiązać metodą wstecznej propagacji błędu, tzn. że dotrzemy do minimum globalnego funkcji kosztu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBa1ySXX-ype",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Trywialne twierdzenie: uczenie sieci zawsze się uda jeśli zastosujemy prawidłowy preprocesor.\n",
    "\n",
    "Jeśli w problemie występują symetrie, to o ile to możliwe warto przenieść ich analizę do fazy preprocesingu, bo powodują one powstanie w funkcji kosztu okresowości, wielokrotnych minimów lokalnych, płaskich dolin i wyżyn.\n",
    "\n",
    "Ze standardowych technik przygotowywania danych (nie tylko dla sieci nuropodobnych) warto rozważyć: \n",
    "* wyskalowanie danych, \n",
    "* normalizację danych, \n",
    "* przeprowadzenie analizy składowych głównych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHzQG5KU-ype",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Generalizacja\n",
    "## O co tu chodzi? \n",
    "![Schemat ilustrujący koncepcję generalizacji](https://brain.fuw.edu.pl/edu/images/f/f7/Generalizacja.png)\n",
    "\n",
    "Na rysunku obok przedstawiona jest schematycznie koncepcja generalizacji. \n",
    "\n",
    "Wyobraźmy sobie, że jest pewna przestrzeń P, która zawiera pary, np. liczb {((a,b), c)}. \n",
    "\n",
    "W tym przykładzie jest to przestrzeń wszystkich odwzorowań $\\mathcal{R}^2 \\rightarrow \\mathcal{R}$. \n",
    "\n",
    "Niektóre z tych par reprezentują pewną konkretną relację R: np. są to pary spełniające warunek $c=\\sqrt{a^2 +b^2}$.\n",
    "\n",
    "Wyobraźmy sobie dalej, że mamy dane dwa skończone zestawy par, które tą relację spełniają, ale oczywiście nie są w stanie obejmować wszystkich możliwych par. \n",
    "\n",
    "Jeden z nich oznaczymy U, a drugi T. Załóżmy, że mamy dwie wersje sieci, które uczymy na zbiorze U (mogą się one różnić architekturą, albo punktem startu procedury uczącej, albo ilością iteracji algorytmu uczącego itp.). \n",
    "\n",
    "Po procesie uczenia sieci te mają mały i porównywalny błąd na zbiorze U, ale jedna z nich nauczyła się relacji wskazanej na rys. jako g1 a druga relacji g2. \n",
    "\n",
    "Na podstawie rezultatów odtwarzania przykładów ze zbioru testowego mówimy, że sieć druga ma lepszą generalizację niż sieć pierwsza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4Vr2yrO-ype",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Jakie mogą być przyczyny złej generalizacji?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkSnjw14-ype",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Architektura nie wystarczająca do reprezentacji relacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMnO8CO_-ype",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Architektura zbyt złożona ... \n",
    "... do danego odwzorowania i zbyt długi proces uczenia:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TA5a-WEv-ypf",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Dotyczy to sytuacji, gdy zbiór uczący zawiera przykłady danej relacji z szumem. Sieć ma tak dużo parametrów, że jest w stanie nauczyć się szczegółów zbioru uczącego nie związanych z interesującą nas relacją. Zjawisko takie nazywamy ''przeuczeniem''."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zARstOo4-ypf",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Przeuczanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRNZ06JY-ypf"
   },
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGH0DR50-ypf",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Uczenie z kryterium wczesnego stopu \n",
    "*  Oprócz zbioru uczącego posiadamy rozłączny z nim zbiór testowy.\n",
    "* W trakcie uczenia obliczamy błąd popełniany przez sieć na zbiorze uczącym i na zbiorze testowym. \n",
    "* W większości przypadków powinniśmy w początkowej fazie uczenia obserwować malenie błędu na obu zbiorach. \n",
    "* Oczekujemy, że w pewnym momencie, kiedy sieć zaczyna się uczyć zbędnych szczegółów to błąd na zbiorze uczącym będzie nadal malał, a na zbiorze testowym zacznie rosnąć. \n",
    "* Uczenie prowadzimy tylko do momentu, kiedy błąd na obu zbiorach maleje. \n",
    "\n",
    "![](https://brain.fuw.edu.pl/edu/images/7/76/Wczesny_stop.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vc3a1Kgb-ypg",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Optymalizacja architektury: Regularyzacja\n",
    "> Pomysł: zacznijmy od dużej sieci i po pewnym cyklu uczenia przeanalizujmy połączenia w sieci usuwając mało istotne połączenia lub jednostki. Następnie powtórzmy uczenie.\n",
    "\n",
    "Można spróbować tak zmodyfikować regułę zmiany wag, aby połączenia nieistotne same dążyły do 0; po standardowym kroku uczenia zmniejszamy wagi: \n",
    "\n",
    "$\\qquad$ $ w_q^{p(j+1)} = (1- \\epsilon) w_q^{p(j)} $   (*)\n",
    "\n",
    "Jest to równoważne modyfikacji funkcji kosztu:\n",
    "\n",
    "$\\qquad$ $J = J_0 + \\frac{1}{2} \\gamma \\sum_{pq}\\left(w_q^p \\right)^2$\n",
    "\n",
    "przy $\\epsilon  = \\alpha \\gamma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESdcYpjk-ypg",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Konsekwencje:\n",
    "* rozwiązanie jest “gładsze”\n",
    "* wygładzenie funkcji kosztu likwiduje część minimów lokalnych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7JiRshw-ypg"
   },
   "source": [
    "Powyższa funkcja kosztu prowadzi do preferowania większej liczby małych wag zamiast jednej dużej. Sytuację poprawia wyrażenie:\n",
    "\n",
    "$\\qquad$ $ J = J_0 +\\frac{1}{2}\\gamma \\sum_{pq} \\frac{\\left(w_q^p\\right)^2}{1+\\left(w_q^p \\right)^2}$\n",
    "\n",
    "co jest równoważne (*) przy \n",
    "\n",
    "$\\qquad$ $\\epsilon_q^p = \\frac{\\alpha \\gamma}{\\left( 1+ \\left(w_q^p \\right)^2\\right)^2}$. \n",
    "\n",
    "Dzięki temu małe wagi zanikają szybciej niż duże. To załatwia problem zanikania niepotrzebnych połączeń. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNBED2KC-ypg"
   },
   "source": [
    "Aby zautomatyzować usuwanie zbędnych jednostek możemy zastosować:\n",
    "\n",
    "$\\qquad$ $ \\epsilon^p = \\frac{\\alpha \\gamma}{ \\left( 1+\\sum_q \\left( w_q^p \\right)^2\\right)^2}$\n",
    "dla wszystkich wejść do jednostki $p$. \n",
    "\n",
    "Powoduje to szybsze zanikanie wag dla jednostek, które mają małe wagi wejściowe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Demo w tensorflow playground \n",
    "\n",
    "[https://playground.tensorflow.org/#activation=linear&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=1&seed=0.23806&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JhcbmFC-ypg",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Metody specyficzne dla sieci \n",
    "* uśrednianie różnych wersji modeli *ensembling*\n",
    "  * trenowanych na różnych podzbiorach danych treningowch\n",
    "  * dla rónych inicjalizacji parametrów\n",
    "  * dla różnych architektur\n",
    "  \n",
    "Te różne pomysły można upakować w jeden model w technice zwanej **dropout** [(Geoffrey Hinton, et al.2012)](https://arxiv.org/abs/1207.0580).\n",
    "-> przejrzyjmy tą pracę (Fig. 1, 2, 6, 7)\n",
    "\n",
    "* W czasie treningu niektóre, losowo wybrane wyjścia z danej warstwy są ignorowane - *wypadają*\n",
    "  * efektywnie wygląda to tak jakby w tym cyklu uczenia ta warstwa miała inną liczbę jednostek i polączeń,\n",
    "  \n",
    "  Jednym z efektów, które sugeruje się, że dropout zapobiega to tzw., złożone ko-adaptacje, czyli proces w którym kolejne jednostki korygują błędy popełnione przez inne jednostki. Losowy dropout niszczy takie ko-adaptacje.\n",
    "  \n",
    " Dropout symuluje rzadką aktywację z danej warstwy, co promuje wytwarznie przez sieć rzadkiej reprezentacji wejścia.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLY7QZDD-ypg",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Jak prowadzić dropout\n",
    "* dropout implementowany jest na zasadzie per-warstwa\n",
    "\n",
    "* może być stosowany po warstwach w pełni połączonych, konwolucyjnych i rekurencyjnych\n",
    "* może wystąpić po dowolnej z wewnętrznych warstw sieci, także zaraz po warstwie wejściowej, nie stosuje się go tylko dla warstwy wyjściowej\n",
    "* hiperparametr określa prawdopodobieństwo wypadnięcia wyjścia - warto sprawdzić w dokumentacji danej biblioteki czy określa on prawdopodobieństwo wypadnięcia, czy pozostawienia wyjścia\n",
    "  * dla pytorch jest to porawdopodobieństwo wypadnięcia\n",
    "  ---\n",
    "  > https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html\n",
    "  >During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution. Each channel will be zeroed out independently on every forward call.\n",
    "  \n",
    "  > This has proven to be an effective technique for regularization and preventing the co-adaptation of neurons as described in the paper Improving neural networks by preventing co-adaptation of feature detectors .\n",
    "\n",
    "  >Furthermore, the outputs are scaled by a factor of  $\\frac{1}{1-p}$  during training. This means that during evaluation the module simply computes an identity function. \n",
    "  ---\n",
    "  \n",
    "* dropout jest wyłączny w trakcie robienia predykcji, i wagi są odpowiednio skalowane \n",
    "* zwykle warsty bliżej wejścia mają mniejszy dropout (prawdopodobieństwo wypadnięcia jednostki ~ 0.2 a jednotki ukryte ~0.5)\n",
    "\n",
    "Przejrzyjmy pracę źródłową z przykładmi (uwaga- w tej pracy p oznacza prawdopodobieństwo pozostawienia jednostki w sieci):\n",
    "[Srivastava(2014), Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n",
    "(Fig. koncepcja 1, przykład zachowania błędu testowego 4, rzadkość reprezentacji: 7, 8, zależność błędu od p 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWTvVmPd-ypg",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Batch normalization\n",
    "Tekst źródłowy [Ioffe, 2015, Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    "\n",
    "* duże sieci neuronowe najczęściej uczy się mini-paczkami (min-batch) danych, tzn. wagi aktualizuje się po przepuszczeniu paczki danych przez sieć do przodu - daje to lepszą estymatę gradientu funkcji kosztu.\n",
    "* wejścia do każdej z warstw zależą od parametrów wszystkich poprzedzających warstw i problem narasta wraz z głębokością sieci.\n",
    "\n",
    "* Motywacją do zaproponowania Batch normalization jest efekt \"internal covariate shift\" - polega on na tym, że po uaktualnieniu wag po mini-batchu rozkłady wejść do warstw głębokich ulegają zmianom. Może to skutkować tym, że algorytm będzie ciągle musiał uczyć się korekt tych zmian rozkładów.\n",
    "* aby temu zapobiec zaproponowano technikę standaryzowania wejść znaną jako **batchnorm**.\n",
    "  * działa ona na każdym wymiarze wejścia do warstwy niezależnie\n",
    "  * polega na odjęciu średniej i podzieleniu przez std  gdzie średnia i std są obliczane dla danego wymiaru wekotra cech po przykładach z mini-batcha (Algorytm 1 w źródłowym tekście). Dodatkowo w procesie uczenia znajdowane są wartości $\\gamma$ i $\\beta$ pozwalające na ponowne przeskalowanie i przesunięcie wyjścia z operacji BN. W czasie treningu sieci uczeniu podlegają parametry sieci oraz  $\\gamma$ i $\\beta$. \n",
    "  * W czasie predykcji do skalowania wejść używane są wartości oczekiwane średniej i std liczone po mini-batcha'ch. (Algorytm 2 w źródłowej pracy).\n",
    "  \n",
    "* stosowanie batch norm pozwala na znacznie szybsze uczenie i lepszą generalizację, ale:\n",
    "  * powody skuteczności batch norm nie są jescze do konca zrozumiane\n",
    "      * wydaje się, że redukcja \"internal covariate shift\" nie jest jedynym powodem sukcesów tej techniki\n",
    "      * inne proponowane przyczyny to [wygładzanie krajobrazu funkcji kosztu](https://arxiv.org/pdf/1805.11604.pdf) (Fig. 4)),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-be4chnn-ypg",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Podsumowując:\n",
    "\n",
    "* dropout - dla każdego przyładu, który przepuszczmy przez sieć w losowy sposób 'wyłączamy' pewne neurony - dane przy przejściu w przód i w tył nie przechodzą przez nie i nie ruszane są ich wagi. Dla kolejnego przykładu zestaw wyłączonych neuronów jest inny.(oryg. art.: https://arxiv.org/pdf/1207.0580.pdf )  (https://www.youtube.com/watch?v=D8PJAL-MZv8 )\n",
    "  * zabieg ten ma wpływ regularyzacyjny na sieć\n",
    "  * intuicyjne wyjaśnienie: \n",
    "    * jednostka nie może w pełni polegać na tym, że zawsze ma dostęp do danych dostarczanych z wejścia i-tego więc nie powinna nadmiernirnie zwiększać wagi dla tego połączenia (trochę jak regularyzacja z normą $L2$). -> zabieg ten zmniejsza prawdopodobieństwo przeuczenia sieci.\n",
    "    * z drugiej strony można na to patrzeć, że \"uczymy wiele wersji\" sieci jednocześnie, a potem uśredniamy po tych wersjach\n",
    "  * prawdopodobieństwo usumięcia neuronu może być różne dla różnych warstw\n",
    "  \n",
    "* mini batch gradient descent - technika przydatna przy bardzo dużych zbiorach danych; \n",
    "  * dzielimy zbiór uczący na podzbiory (\"batch\"), \n",
    "  * obliczamy skumulowany gradient dla danego batcha \n",
    "  * zmieniamy wagi, \n",
    "  * bierzemy kolejny batch \n",
    "\n",
    "* batch normalization (oryginalny art. z tym pomysłem: https://arxiv.org/pdf/1502.03167v3.pdf )( https://www.youtube.com/watch?v=tNIpEZLv_eg )\n",
    "  * normalizacja (odjęcie średniej i podzielenie przez st. odchylenie) wejść dla pojedynczego neuronu \"poprawia\" kształt funkcji kosztu czyniąc ją bardziej symetryczną\n",
    "  * ta intuicja jest przeoszona do normalizacji każdej warstwy w sieci głębokiej - wyjścia takiej warstwy są normalizowane (średnia i standardowe odchylanie są obliczane w obrębie mini-batcha). Warto zadbać o to aby głębokim warstwom umożliwić niekoniecznie pracę ze średnia 0 i wariancją 1 - stąd dodaje się trenowalne parametry modyfikujące średnią i wariancję. Zobaczmy to w źródłowym art. https://arxiv.org/pdf/1502.03167v3.pdf sekcja 3.\n",
    "  \n",
    "  \n",
    "\n",
    "* Batchnorm i dropout raczej nie powinny być używane w tej samej sieci - statystyki używane do normalizacji aktywacji mogą stać się zaszumione przez losowe usunięcie jednostek w procedurze dropoutu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvsDTp8U-yph",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Diagnostyka i debugowanie algorytmu uczącego\n",
    "\n",
    "Załóżmy, że zaimplementowaliśmy algorytm uczący na określonym (niewielkim) zbiorze danych. Mamy 20 % błędnych decyzji. Co z tym robić dalej?\n",
    "\n",
    "Potencjalnie można:\n",
    "* poprawić algorytm\n",
    "* zdobyć więcej przykładów do ciągu uczącego\n",
    "* wypróbować więcej cech lub ograniczyć przestrzeń cech\n",
    "* pouczyć dłużej albo zmienić algorytm optymalizacyjny\n",
    "* zmienić parametry uczenia (współczynnik szybkości, regularyzacji, itp.)\n",
    "Każda z tych metod naprawia jakiś (ale inny) problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_Xt47ek-yph",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Aby zdiagnozować problem dobrze jest analizować wykresy błędu od długości uczenia: \n",
    "  * czy algorytm jest zbieżny? \n",
    "    * jeśli nie to możemy próbować poprawić to zmniejszając prędkość uczenia lub zmieniając procedurę optymalizacyjną\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r387r9qY-yph",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * Jeśli błąd na zbiorze treningowym jest dużo niższy niż na testowym to możemy mieć problem przeuczenia\n",
    "    * można: dodać przykładów, zmniejszyć rozmiar wejścia, włączyć regularyzację\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eks6xXK-yph",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * Duży błąd na zbiorze uczącym i na testowym -> źle dobrane cechy lub struktura klasyfikatora \n",
    "    *  zmienić zestaw cech \n",
    "    * wzbogacić strukturę klasyfikatora "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mlawwou-ypX",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Przyspieszanie uczenia \n",
    "## Bezwładność \n",
    "![Przykładowa ewolucja wag na tle konturu funkcji kosztu. Lewy ślad: brak bezwładności, prawy z włączoną bezwładnością](https://brain.fuw.edu.pl/edu/images/0/08/Bezwładnosc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0EqZvZw-ypX",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Uwaga:** w tym wykładzie górny inedks w nawiasie oznacza kork uczenia, np.  $\\Delta w^{(j)}$ oznacza zmianę wagi w $j$-tym kroku.\n",
    "\n",
    "Bez bezwładności:\n",
    "\n",
    "$\\qquad$  $w^{(j+1)} = w^{(j)} - \\alpha_1 \\left.\\frac{\\partial J}{\\partial w}\\right|_{w=w^{(j)}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQTk8jML-ypX",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Dodanie członu bezwładności do formuły zmiany wag:\n",
    "\n",
    "$\\qquad$  $m^{(j)} = \\alpha_2 m^{(j-1)} - \\alpha_1  \\left.\\frac{\\partial J}{\\partial w}\\right|_{w=w^{(j)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aj_YoRtm-ypY",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\qquad$ $w^{(j+1)} = w^{(j)} + m^{(j)}  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0B_W70R-ypY",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Dla prawie płaskiej powierzchni kosztu (tzn. $m^{(j+1)} \\approx m^{(j)}$) efektywny współczynnik uczenia jest\n",
    "$ \\frac{1}{1-\\alpha_2}$ razy większy niż w przypadku algorytmu bez bezwładności. \n",
    "\n",
    "* Dla typowych wartości $\\alpha_1 = 0.1$ i $\\alpha_2 = 0.9$ otrzymujemy około 10 krotne przyspieszenie!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiyHMZ_S-ypY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## bezwładność Nesterova\n",
    "Nesterov accelerated gradient (NAG). \n",
    "\n",
    "Intuicja, która stoi za algorytmem Nesterova polega na:\n",
    ">\"popatrz do  przodu zanim się skoczysz\".\n",
    "\n",
    "\n",
    "* w przypadku zwykłej bezwładności wiemy, że zmienimy wagę o\n",
    "$\\qquad$  $\\alpha_2  m^{(j-1)}$ $\\qquad$  \n",
    "z drobną korektą uwzględniającą lokalny gradient, tzn. w miejscu $w^{(j)}$. \n",
    "\n",
    "* A może by sprawdzić gradient powierzchni kosztu w miejscu, do którego skoczylibyśmy w oparciu o samą bezwładność, czyli w miejscu \n",
    "\n",
    "$\\qquad$  $w_{(w przodzie)} = w^{(j)}+ \\alpha_2 m^{(j-1)} $ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQC3FamL-ypZ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\qquad$ $m^{(j)} = \\alpha_2  m^{(j-1)} - \\left. \\alpha_1  \\frac{\\partial J}{\\partial w} \\right|_{w=w_{(w przodzie)}} =  \\alpha_2  m^{(j-1)} - \\left. \\alpha_1  \\frac{\\partial J}{\\partial w} \\right|_{w=w^{(j)} + \\alpha_2 m^{(j-1)}}$\n",
    "\n",
    "$\\qquad$ $w^{(j+1)} = w^{(j)} + m^{(j)}$\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2054/1*6MEi74EMyPERHlAX-x2Slw.png\">\n",
    "\n",
    "Ilustracja zaczerpnięta z bloga: https://towardsdatascience.com/learning-parameters-part-2-a190bef2d12\n",
    "Tam, do obejrzenia animacje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQkjRz2N-ypZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Adaptacyjny dobór parametrów \n",
    "Kiedy obserwujemy proces minimalizacji funkcji błędu to często widać, że stała wartość parametru uczenia $\\alpha_1$ nie jest optymalna. \n",
    "* Czasami widać, że funkcja długi czas maleje prawie monotonicznie - wtedy lepiej byłoby mieć większą wartość  $\\alpha_1$,\n",
    "* kiedy indziej bardzo oscyluje - to świadczy o zbyt dużej wartości $\\alpha_1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRl6BfJ7-ypa",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Prosty pomysł \n",
    "Jednym z prostych pomysłów na zautomatyzowanie procesu dobierania wartości $\\alpha_1$ jest następujący schemat zmiany tego parametru:\n",
    "\n",
    "$\\qquad$ $\n",
    "\\Delta \\alpha_1  = \\left\\{ \n",
    "\\begin{array}{lcl}\n",
    "+ a& \\text{dla} & \\Delta J <0 \\\\\n",
    "-b \\alpha_1 & \\text{dla} & \\Delta J >0 \\\\\n",
    "0 & \\text{dla pozostalych przypadkow}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$\n",
    "\n",
    "Po wykonaniu kroku prowadzącego do zwiększenia funkcji kosztu warto go wycofać."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xUtpH19-ypa",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Elastyczna wsteczna propagacja błędu \n",
    "Resilient Backpropagation — do zmiany wag wykorzystujemy jedynie informację o znaku gradientu. W poniższych formułach $w_q^p$ to waga łącząca wyjście neuronu $q$ z odpowiednim (q-tym) wejściem neuronu $p$.\n",
    "\n",
    "$\\qquad$ $\n",
    "\\Delta w_q^{p(j)}  = - \\text{sign} \\left(\\frac{\\partial J}{\\partial w_p^q}\\right) \\Delta_q^{p(j)} \n",
    "$\n",
    "gdzie: $J$ jest miarą błędu po prezentacji wszystkich bodźców, zaś $\\Delta_q^{p(j)}$:\n",
    "$\\qquad$ $\n",
    "\\Delta_q^{p(j)}  = \\left\\{ \n",
    "\\begin{array}{lcl}\n",
    "\\eta^+ \\Delta_q^{p(j-1)} & \\text{dla} & \\frac{\\partial J^{(j-1)}}{\\partial w_p^q}\\frac{\\partial J^{(j)}}{\\partial w_p^q} >0 \\\\\n",
    "\\eta^- \\Delta_q^{p(j-1)} & \\text{dla} & \\frac{\\partial J^{(j-1)}}{\\partial w_p^q}\\frac{\\partial J^{(j)}}{\\partial w_p^q} <0 \\\\\n",
    "\\Delta_q^{p(j-1)} & \\text{dla pozostalych przypadkow}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$\n",
    "\n",
    "gdzie: $ 0 < \\eta^- < 1 < \\eta^+$. \n",
    "\n",
    "Dodatkowo ustala się ograniczenie na możliwe wartości $ \\Delta_{min} < \\Delta_p^q < \\Delta_{max}$. \n",
    "\n",
    "Standardowo $\\Delta_{min} \\approx 10^{-6}$ a $ \\Delta_{max} \\approx 50$. \n",
    "\n",
    "Dla sigmoidalnych funkcji odpowiedzi metoda ta może poprawić uczenie w obszarze ogonów sigmoidy, gdzie wartość gradientu jest bardzo mała."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVraUz8k-ypb",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Metoda najszybszego spadku \n",
    "Kolejnej wartości wagi szukamy wzdłuż prostej wyznaczonej przez poprzedni wektor wag $w^{(j)}$ i kierunek $d^{(j)}$, zmieniając $\\lambda$ tak, aby zminimalizować w danym kierunku $J$:\n",
    "\n",
    "$\\qquad$ $w^{(j+1)} = w^{(j)} + \\lambda d^{(j)}$\n",
    "\n",
    "Kierunek $d$ wybieramy przeciwnie do gradientu $J$\n",
    "\n",
    "$\\qquad$ $ d^{(j)} = -\\nabla J(w^{(j)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nODX8ynX-ypc",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Zauważmy, że stary i nowy kierunek minimalizacji są ortogonalne, bo $\\lambda$ jest dobrana tak, aby minimalizować funkcję kosztu w kierunku $d^{(j)}   $ tzn.:\n",
    "\n",
    "$\\qquad$ $\\frac{\\partial}{\\partial \\lambda} J(w^{(j)} + \\lambda d^{(j)}) = 0 $\n",
    "\n",
    "Ale rozwijając powyższy wzór widzimy, że:\n",
    "\n",
    "\n",
    "$\\qquad$ $\\frac{\\partial}{\\partial \\lambda} J(w^{(j)} + \\lambda d^{(j)}) =  \\frac{\\partial J\\left(w^{(j+1)}\\right)}{\\partial w} \\frac{\\partial (w^{(j)}+ \\lambda d^{(j)})}{\\partial\\lambda}  = \\nabla J(w^{(j+1)}) \\cdot d^{(j)} = -d^{(j+1)} \\cdot d^{(j)} =0\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6ijIDyl-ypb",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://miro.medium.com/max/936/1*8lDYTCFKGAUHcsJpbzdGsQ.gif\" width=\"800\">\n",
    "\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rlpg3sOO-ypb",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://miro.medium.com/max/1400/1*fRGHjjqjl5P6IArtZpx_Hg.jpeg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YYTRV7m-ypb"
   },
   "source": [
    "            \n",
    "Ilustracje pochodzą z bloga: https://towardsdatascience.com/learning-parameters-part-4-6a18d1d3000b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiyrJ4lR-ypc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Metoda gradientu sprzężonego\n",
    "Poprzednią metodę można udoskonalić przez rezygnację z ortogonalności kolejnych kroków:\n",
    "\n",
    "$\\qquad$ $d^{(j+1)} = -\\nabla J \\left( w^{(j+1)} \\right) + \\beta d^{(j)}$\n",
    "\n",
    "i trzeba chytrze dobrać $\\beta$ tak, aby jak najmniej psuć efekt osiągnięty w poprzednim kroku. Nowy kierunek szukania powinien więc być taki, aby z dokładnością pierwszego rzędu nie zmieniał składowej gradientu, która w poprzednim kroku została wyzerowana. A zatem chcemy, aby z dokładnością do wyrazów pierwszego stopnia, spełnione było:\n",
    "\n",
    "$\\qquad$ $ d^{(j)} \\cdot \\nabla J\\left( w^{(j)} + \\lambda d^{(j+1)} \\right) = 0 $\n",
    "\n",
    "praktyczny sposób na znalezienie $ \\beta$ spełniającego powyższy warunek podaje reguła Polaka-Ribiere‘a: \n",
    "\n",
    "$\\qquad$ $ \\beta = \\frac{\\left( \\nabla J\\left (w^{(j+1)} \\right)  - \\nabla J \\left( w^{(j)}\\right)\\right) \\cdot \\nabla J\\left(w^{(j+1)}\\right)}{\n",
    "\\left( \\nabla J \\left(w^{(j)}\\right)\\right)^2}$\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/Conjugate_gradient_illustration.svg/1280px-Conjugate_gradient_illustration.svg.png\" width=\"400\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mf6lOWOJ-ypc",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Indywidualizacja szybkości zmian dla każdej z wag\n",
    "\n",
    "Przypomnijmy sobie z poprzedniego wykładu, że dla pojedynczego neuronu mieliśmy \n",
    "\n",
    "$\\qquad$ $ \\Delta w_i^{(j)} = \\eta \\frac{df(a)}{d a}\\left(z^{(j)} - y^{(j)}\\right)x_i^{(j)} = \\eta \\delta^{(j)}x_i^{(j)}$\n",
    "\n",
    "gdzie wprowadziliśmy:\n",
    "\n",
    "$\\qquad$ $\\delta^{(j)} = \\frac{df(a)}{da} \\left( z^{(j)}- y^{(j)}\\right)$\n",
    "\n",
    "Zauważmy, że:\n",
    "\n",
    "* _zmiana wagi zależy od gradientu, ale także od wejścia do neuronu!_\n",
    "\n",
    "* Jeśli któreś z wejść jest rzadkie (tzn. jest 0 dla wielu przykładów), ale z drugiej strony jest ważne, to dotychczasowe startegie uczenia będą niedouczały tego wejścia. \n",
    "\n",
    "Teraz zaprezentujemy rozwój algorytmów, kótre miały to na uwadze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCd7w1dF-ypc",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### AdaGrad - adaptive gradient algorithm\n",
    "\n",
    ">Żeby wyrównać szanse wszystkich wag, powinniśmy zmiejszać szybkość uczenia dla wag, które są zmieniane często.\n",
    "\n",
    "Miarą tego jak dużo zmian wagi $w$ uczyniliśmy może być suma kwadratów gradientów:\n",
    "\n",
    "$\\qquad$ $v_w^{(j)} =  v_w^{(j-1)} +(\\nabla_{w^{(j)}}J)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhiXEInR-ypc",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\qquad$ $w^{(j+1)} = w^{(j)} - \\frac{\\eta}{\\sqrt{v_w^{(j)} +\\epsilon}} \\nabla_{w^{(j)}}J$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhBhyf17-ypd",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To rozwiązanie ma dość oczywisty problem. Jeśli do zoptymalizowania jakiejś wagi faktycznie potrzeba wiele kroków to możemy za bardzo zmniejszyć tempo uczenia i algorytm utknie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITGDww9Z-ypd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RMSProp — Root Mean Square Propagation\n",
    "Rozwiązanie, które zapropopnowano aby zaradzić temu problemowi polega na zmodyfikowaniu sposobu gromadzenia informacji o zmianach wag. \n",
    "\n",
    "$\\qquad$ $v_w^{(j)} =  \\beta v_w^{(j-1)} +(1-\\beta)(\\nabla_{w^{(j)}}J)^2$\n",
    "\n",
    "przy czym $0\\lt \\beta \\lt 1$\n",
    "\n",
    "Powoduje to, że jeśli $J$ jest płaska w kierunku pewnego $w$ to $v_w$ zmniejsza się geometrycznie, czyli \"odblokowuje\" szybsze uczenie w danym kierunku.\n",
    "\n",
    "Sama reguła zmiany wag jest taka sama jak poprzednio.\n",
    "\n",
    "$\\qquad$ $w^{(j+1)} = w^{(j)} - \\frac{\\eta}{\\sqrt{v_w^{(j)} +\\epsilon}} \\nabla_{w^{(j)}}J$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGzZlCaS-ypd",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Algorytm Adam\n",
    "Adaptive Moment Estimation (Adam) [https://arxiv.org/pdf/1412.6980.pdf] jest metodą, która dobiera prędkośc uczenia w sposób adaptacyjny. Metoda opiera się na adaptacyjnym estymowaniu momentów (rozkładu) gradientów, stąd jej nazwa.\n",
    "\n",
    ">Intuicja jaka za nią stoi to: naprawiamy tempo ucznia AdaGrad tak jak w RMSProp, a dodatkowo zastępujemy lokalny gradient przez średnią biegnącą gradientu.\n",
    "\n",
    "Oznaczmy:\n",
    "$\\qquad$ $g_{(j)} = \\nabla_{w^{(j)}}J$\n",
    "\n",
    "Estymata pierwszego momentu (średniej biegnącej) gradientów:\n",
    "\n",
    "$\\qquad$$m_t = \\beta_1 m_{t−1} + (1 − \\beta_1)g_{(j)}$\n",
    "\n",
    "i drugiego momentu (niecentralna wariancja biegnąca) gradientów:\n",
    "\n",
    "$\\qquad$$v_t = \\beta_2 v_{t−1} + (1 − \\beta_2)g_{(j)}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtZVpjtF-ypd",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Autorzy metody zauważyli, że te estymatory momentów mają tendencję do dążenia w kierunku 0. Aby temu przeciwdziałać wprowadzili korektę do powyższych wartości (zauważmy, że $\\beta$ jest podnoszona do potęgi $j$ - wraz z kolejnymi krokami uczenia ta korekta zanika):\n",
    "\n",
    "$\\qquad$ $\\hat{m}_{(j)} = \\frac{m_{(j)}}{1-\\beta_1^{j}}$\n",
    "$\\qquad$ $\\hat{v}_{(j)} = \\frac{v_{(j)}}{1-\\beta_2^{j}}$\n",
    "\n",
    "Te skorygowane estymatory są stosowane do uaktualniania parametrów:\n",
    "\n",
    "$\\qquad$ $w^{(j+1)} = w^{(j)}  − \\frac{\\eta}\n",
    "{\\sqrt\n",
    "{\\hat{v}_{(j)} +\\epsilon}\n",
    "}\n",
    "\\hat{m}_{(j)}$\n",
    "\n",
    "Proponowane są następujace wartości domyślne:$\\beta_1 = 0.9$, $\\beta_2 = 0.999$ i $\\epsilon = 10^{-8}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## AdamW: Adam with L2 regularization and with decoupled weight decay\n",
    "\n",
    "https://arxiv.org/pdf/1711.05101.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Eotirep-ypd",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ilustracja właściwości algorytmów z indywidualizacją szybkości uczenia wag: https://towardsdatascience.com/learning-parameters-part-5-65a2f3583f7d\n",
    "\n",
    "Przegląd współczesnych gradientowych algorytmów optymalizacyjnych: https://arxiv.org/pdf/1609.04747.pdf\n",
    "\n",
    "Animacje ilustrujące szybkość zbiegania dla różnych kształtów funkcji kosztu: https://imgur.com/a/Hqolp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsTwCizE-ypd",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Podsumowanie metod przyspieszania uczenia\n",
    "\n",
    "* Ogólnie: Za szybkość płacimy ilością koniecznej pamięci i wymaganą precyzją obliczeń\n",
    "* Algorytm Adam i spadek gradientowy z bezwładnością Nesterova są obecnie najpopularniejsze\n",
    "* Resilient Backpropagation: wydaje się być najlepszy w problemach rozpoznawania wzorców, ale nie nadaje się w zasadzie do aproksymacji funkcji. Nie jest pamięciożerny.\n",
    "* Algorytm gradientów sprzężonych: jest najbardziej uniwersalnym algorytmem. Ma umiarkowane wymagania co do ilości pamięci.\n",
    "* Zwykła metoda gradientowa: jest najwolniejsza, ale może to być użyteczne jeśli bardziej niż na czasie zależy nam na generalizacji.\n",
    "* Nieliniowość typu ReLu jest odporna na problem wysycania gradientu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vIPNmtG-ype",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Problem minimów lokalnych \n",
    "Wszystkie metody minimalizacji funkcji kosztu mogą utknąć w minimach lokalnych. Kilka metod, które mogą pomóc zmniejszyć problemy z minimami lokalnymi:\n",
    "* uniknięcie wysycenia sigmoid już na samym początku uczenia. Np. dla unormowanego wejścia i dla sigmoidy z $\\beta = 1 $ wybranie początkowych wag losowych o takich wartościach, że średnie pobudzenie neuronu $a$ jest mniejsze, ale nie za bardzo niż 1 (można losować wagi rzędu $\\sqrt \\frac{1}{k_i}$\tgdzie $k_i$ ilość wejść do jednostki $i$);\n",
    "* poprawianie wag po każdej prezentacji wzorca, przy czym wzorce prezentowane są w losowej kolejności;\n",
    "* zastosowanie jednostek stochastycznych — gradient oraz dodatkowy parametr T temperatura kontrolują prawdopodobieństwo zmiany wagi w określonym kierunku;\n",
    "* delikatne losowe zmiany wag;\n",
    "* przy każdej prezentacji wzorca dodawanie do niego troszkę szumu. Dodanie szumu zawsze spowolni proces uczenia, przy czym mała dawka może pomóc uniknąć minimów lokalnych, duża - znacznie spowalnia uczenie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZfXZ-HH-yph"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qqWpOUi-ypi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wJSEds8-ypi"
   },
   "source": [
    "## Metody quasi-Newtona\n",
    "\n",
    "Oryginalna metoda Newtona polega na minimalizacji funkcji kosztu z wykorzystaniem drugich pochodnych.\n",
    "Rozwijając $J(w)$ wokół bieżącego wektora wag $w_0$ mamy: \n",
    "\n",
    "$\\qquad$ $J(w)=J(w_0)+(w-w_0)\\cdot \\nabla J\\left( w_0\\right) + \\frac{1}{2} (w - w_0) \\cdot H \\cdot(w - w_0) +... $ (∗)\n",
    "\n",
    "gdzie: H to ''hesjan'' (macierz drugich pochodnych cząstkowych $ H_{ij} =\\frac{\\partial^2 J}{\\partial w_i \\partial w_j}$ )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJ77qNGw-ypi"
   },
   "source": [
    "Różniczkowanie (* * *) daje: \n",
    "\n",
    "$\\qquad$ $ \\nabla J(w) = \\nabla J(w_0) + H \\cdot (w - w_0) + \\dots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgE9Zhuo-ypi"
   },
   "source": [
    "chcemy znaleźć minimum $J$ czyli spełnić warunek $ \\nabla J(w) = 0$:\n",
    "\n",
    "$\\qquad$ $ \\nabla J(w_0) + H \\cdot (w - w_0) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAEh7ATK-ypi"
   },
   "source": [
    "stąd: \n",
    "\n",
    "$\\qquad$ $w  = w_0 + H^{-1} \\nabla J \\left(w_0 \\right) $\n",
    "\n",
    "Wzór ten można stosować iteracyjnie.\n",
    "\n",
    "Metoda w oryginalnej postaci jest bardzo kosztowna obliczeniowo ($O(n^3)$) i jest niestabilna numerycznie. Stąd też realne implementacje są nieco inne i zasadniczo polegają na iteracyjnej aktualizacji hesjanu. Zwykle wymaga mniej kroków niż metoda gradientów sprzężonych, ale w każdym kroku jest więcej obliczeń i trzeba mieć pamięć na przechowywanie hesjanu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oe166Gm-ypi"
   },
   "source": [
    "## Algorytm Lavenberg-Marquardt'a\n",
    "Metoda ta korzysta z faktu, że hesjan może być przybliżony przez:\n",
    "\n",
    "$\\qquad$ $ \\mathbf{H} \\approx \\mathbf{J}^T \\mathbf{J}$\n",
    "\n",
    "gdzie: $\\mathbf{J}$ — macierz jakobiego (macierz pierwszych pochodnych cząskowych) natomiast\n",
    "\n",
    "$\\qquad$ $\\nabla J \\left(w^{(j)}\\right) = \\mathbf{J}^T (z^{(j)} - y^{(j)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKLlqptq-ypi"
   },
   "source": [
    "W metodzie tej wagi zmieniamy:\n",
    "\n",
    "$\\qquad$ $w^{(j+1)} = w^{(j)} + [\\mathbf{J}^T\\mathbf{ J} + \\mu \\mathbf{I}]^{-1} \\mathbf{J}^T (z^{(j)} - y^{(j)})$\n",
    "\n",
    "dla $ \\mu = 0$ jest to metoda Newtona z przybliżoną wartością hesjanu, dla $ \\mu$ dużego metoda dąży do zwykłej metody gradientowej. Metoda Newtona jest szybsza i dokładniejsza w pobliżu minimum $J$.\n",
    "\n",
    "$ \\mu$ jest zmniejszane po każdym udanym kroku a zwiększane jeśli w danym kroku $J$ wzrosło."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "Wykład11_sieci_cd.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "livereveal": {
   "progress": true,
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "serif",
   "transition": "fade",
   "width": 1600
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
